{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"6Fam410cQUPp","executionInfo":{"status":"ok","timestamp":1682523746913,"user_tz":240,"elapsed":4291,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow\n","from gensim.models.word2vec import Word2Vec\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","from keras.layers import Dense, Dropout, Conv1D, MaxPool1D, GlobalMaxPool1D, Embedding, Activation\n","from keras.preprocessing.text import Tokenizer\n","# from keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem.snowball import PorterStemmer\n","from sklearn import preprocessing\n","import gensim\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","import string\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from gensim.models import Word2Vec\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n","from tensorflow.keras.models import Sequential\n","import nltk"]},{"cell_type":"code","source":["def preprocess_text(sen):\n","    # Remove punctuations and numbers\n","    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n","\n","    # Single character removal\n","    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n","\n","    # Removing multiple spaces\n","    sentence = re.sub(r'\\s+', ' ', sentence)\n","    \n","    stops = stopwords.words('english')\n","    #print(stops)\n","    porter = PorterStemmer()\n","    for word in sentence.split():\n","        if word in stops:\n","            sentence = sentence.replace(word, '')\n","        sentence = sentence.replace(word, porter.stem(word))\n","    return sentence.lower()"],"metadata":{"id":"q5vI_KKRQhi4","executionInfo":{"status":"ok","timestamp":1682523746914,"user_tz":240,"elapsed":8,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","df = pd.read_csv('../content/drive/MyDrive/Reviews.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nfnuWQq1QhlW","executionInfo":{"status":"ok","timestamp":1682523782562,"user_tz":240,"elapsed":35655,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}},"outputId":"f7ffc229-f207-4106-ea08-aa543e7d7194"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["\n","df = df[['Text','Score']]\n","df['Score'].isnull().sum()\n","df['Score'].isnull().sum()\n","df.drop_duplicates(subset=['Text','Score'],keep='first',inplace=True)\n","\n","def set_sent(score):\n","    if score<=2:\n","        return 0\n","    elif score==3:\n","        return 1\n","    else:\n","        return 2\n","\n","df['sentiment']=df['Score'].apply(set_sent)\n","df = df[['Text','sentiment']]\n","\n","# Separate into three sentiment groups\n","df_neg1 = df[df['sentiment']==0]\n","df_0 = df[df['sentiment']==1]\n","df_1 = df[df['sentiment']==2]\n","\n","n = 10000\n","\n","df_neg1 = df_neg1.sample(n=n, random_state=42, replace=False)\n","df_0 = df_0.sample(n=n, random_state=42, replace=False)\n","df_1 = df_1.sample(n=n, random_state=42, replace=False)\n","# print(\"df_neg1: \", df_neg1)\n","# print(\"df_0: \", df_0)\n","# print(\"df_1: \", df_1)\n","\n","sub_df = pd.concat([df_neg1, df_0, df_1], axis=0)\n","X = sub_df['Text']\n","\n","y = sub_df['sentiment']"],"metadata":{"id":"Do5l28aCRafi","executionInfo":{"status":"ok","timestamp":1682523783495,"user_tz":240,"elapsed":934,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["mes = []\n","for i in X:\n","    mes.append(i.split())\n","print(mes[:2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ptIxHOUKQhn8","executionInfo":{"status":"ok","timestamp":1682523783851,"user_tz":240,"elapsed":357,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}},"outputId":"191e41aa-894b-47df-e4d3-aa1848113df3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[['Vile', 'and', 'revolting', '\"tahini\";', 'absolutely', 'ruined', 'a', 'batch', 'a', 'hummus.', 'This', 'tahini', 'has', 'a', 'bitter,', 'metallic', 'and', 'chemical', 'like', 'taste.', 'It', 'is', 'not', 'a', 'matter', 'of', 'not', 'knowing', 'how', 'to', 'use', 'it', '(it', 'separates,', 'mix', 'it', 'up', 'just', 'like', 'natural', 'peanut', 'butter)', 'it', 'is', 'a', 'matter', 'of', 'an', 'awful', 'product.', 'Stay', 'far,', 'far', 'away', 'and', 'ignore', 'the', '5', 'star', 'reviews', 'which', 'sound', 'suspiciously', 'like', 'they', 'were', 'written', 'by', 'Joyva.', 'There', 'is', 'far', 'better', 'tahini', 'out', 'there.'], ['They', 'will', 'send', 'you', '70%', 'cocoa', 'lindt', 'chocolate', 'but', 'it', 'has', 'a', '\"new', 'recipe\".', \"It's\", '30', 'calories', 'more', 'a', 'serving,', 'all', 'sugar,', 'and', 'takes', 'like', 'crappy', 'milk', 'chocolate', \"you'd\", 'get', 'in', 'a', 'cheap', 'easter', 'bunny.', 'Has', 'none', 'of', 'the', 'cocoa', 'bite', 'that', 'it', 'used', 'to.', 'This', 'is', 'kind', 'of', 'sad,', 'since', 'this', 'chocolate', 'used', 'to', 'be', 'the', 'best', 'readily', 'available', 'dark', 'chocolate', 'on', 'the', 'market.<br', '/><br', '/>If', \"you're\", 'looking', 'for', 'a', 'dark', 'chocolate', \"that's\", 'kind', 'of', 'low', 'in', 'carbs,', 'this', \"isn't\", 'it.', 'Save', 'yourself', 'some', 'money', 'and', 'buy', 'a', 'hersey', 'bar.']]\n"]}]},{"cell_type":"code","source":["w2v_model = Word2Vec(mes, window=10, min_count=1, workers=16)\n","print(w2v_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GhChcFxvQhqO","executionInfo":{"status":"ok","timestamp":1682523809822,"user_tz":240,"elapsed":25975,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}},"outputId":"e9b9290e-98e3-4915-ca89-abc56e532bd4"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Word2Vec<vocab=120442, vector_size=100, alpha=0.025>\n"]}]},{"cell_type":"code","source":["# Preprocess the text data\n","import nltk\n","nltk.download('stopwords')\n","import nltk\n","nltk.download('punkt')\n","stop_words = set(stopwords.words('english'))\n","def preprocess(text):\n","    text = text.lower()\n","    text = ''.join([word for word in text if word not in string.punctuation])\n","    tokens = word_tokenize(text)\n","    tokens = [word for word in tokens if word not in stop_words]\n","    return ' '.join(tokens)\n","\n","X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=0.2)\n","\n","X_train = X_train.apply(preprocess)\n","X_test = X_test.apply(preprocess)\n","\n","max_length = 100\n","\n","# Tokenize the text data\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(X_train)\n","X_train = tokenizer.texts_to_sequences(X_train)\n","X_test = tokenizer.texts_to_sequences(X_test)\n","X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n","X_test = pad_sequences(X_test, maxlen=max_length, padding='post')\n","vocab_size = len(tokenizer.word_index) + 1\n","# Create a weight matrix for the embedding layer\n","embedding_matrix = np.zeros((vocab_size, 100))\n","for word, i in tokenizer.word_index.items():\n","    if word in w2v_model.wv:\n","        embedding_matrix[i] = w2v_model.wv[word]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uugRQEMFQhtf","outputId":"79134cfb-39c9-4994-d32b-5adac9d6ce90","executionInfo":{"status":"ok","timestamp":1682523823238,"user_tz":240,"elapsed":13435,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["# Define the CNN model\n","from keras.models import Sequential\n","from keras import layers\n","\n","model = Sequential()\n","model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_length, trainable=False))\n","model.add(Conv1D(256, 5, activation='relu'))\n","model.add(MaxPooling1D(5))\n","model.add(Conv1D(256, 5, activation='relu'))\n","model.add(MaxPooling1D(5))\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=200, batch_size=64, validation_data=(X_test, y_test))"],"metadata":{"id":"TS39qOdJQr2v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682524269153,"user_tz":240,"elapsed":445929,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}},"outputId":"8e1d7794-997b-4045-a39b-45cdcd7bbe67"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","375/375 [==============================] - 13s 6ms/step - loss: -1672388.1250 - accuracy: 0.3421 - val_loss: -11094682.0000 - val_accuracy: 0.3422\n","Epoch 2/200\n","375/375 [==============================] - 3s 7ms/step - loss: -73571240.0000 - accuracy: 0.3435 - val_loss: -214829520.0000 - val_accuracy: 0.3435\n","Epoch 3/200\n","375/375 [==============================] - 2s 6ms/step - loss: -513779744.0000 - accuracy: 0.3438 - val_loss: -1066631232.0000 - val_accuracy: 0.3435\n","Epoch 4/200\n","375/375 [==============================] - 2s 5ms/step - loss: -1845337984.0000 - accuracy: 0.3446 - val_loss: -3275114240.0000 - val_accuracy: 0.3422\n","Epoch 5/200\n","375/375 [==============================] - 2s 5ms/step - loss: -4700489216.0000 - accuracy: 0.3441 - val_loss: -7365468160.0000 - val_accuracy: 0.3422\n","Epoch 6/200\n","375/375 [==============================] - 2s 5ms/step - loss: -9664361472.0000 - accuracy: 0.3453 - val_loss: -14150724608.0000 - val_accuracy: 0.3418\n","Epoch 7/200\n","375/375 [==============================] - 2s 5ms/step - loss: -17340055552.0000 - accuracy: 0.3443 - val_loss: -24252215296.0000 - val_accuracy: 0.3412\n","Epoch 8/200\n","375/375 [==============================] - 2s 5ms/step - loss: -28374566912.0000 - accuracy: 0.3434 - val_loss: -38301982720.0000 - val_accuracy: 0.3420\n","Epoch 9/200\n","375/375 [==============================] - 3s 7ms/step - loss: -43278647296.0000 - accuracy: 0.3441 - val_loss: -56869797888.0000 - val_accuracy: 0.3418\n","Epoch 10/200\n","375/375 [==============================] - 3s 8ms/step - loss: -62403268608.0000 - accuracy: 0.3444 - val_loss: -79893233664.0000 - val_accuracy: 0.3418\n","Epoch 11/200\n","375/375 [==============================] - 2s 5ms/step - loss: -86192463872.0000 - accuracy: 0.3440 - val_loss: -108636086272.0000 - val_accuracy: 0.3418\n","Epoch 12/200\n","375/375 [==============================] - 2s 6ms/step - loss: -115461627904.0000 - accuracy: 0.3445 - val_loss: -143366471680.0000 - val_accuracy: 0.3420\n","Epoch 13/200\n","375/375 [==============================] - 2s 5ms/step - loss: -150704029696.0000 - accuracy: 0.3440 - val_loss: -185274580992.0000 - val_accuracy: 0.3418\n","Epoch 14/200\n","375/375 [==============================] - 2s 6ms/step - loss: -192516145152.0000 - accuracy: 0.3443 - val_loss: -234512760832.0000 - val_accuracy: 0.3418\n","Epoch 15/200\n","375/375 [==============================] - 2s 6ms/step - loss: -241202315264.0000 - accuracy: 0.3441 - val_loss: -291559669760.0000 - val_accuracy: 0.3420\n","Epoch 16/200\n","375/375 [==============================] - 2s 5ms/step - loss: -297598156800.0000 - accuracy: 0.3442 - val_loss: -356810784768.0000 - val_accuracy: 0.3418\n","Epoch 17/200\n","375/375 [==============================] - 2s 5ms/step - loss: -362002677760.0000 - accuracy: 0.3440 - val_loss: -431468347392.0000 - val_accuracy: 0.3418\n","Epoch 18/200\n","375/375 [==============================] - 2s 5ms/step - loss: -435191676928.0000 - accuracy: 0.3440 - val_loss: -515979083776.0000 - val_accuracy: 0.3418\n","Epoch 19/200\n","375/375 [==============================] - 2s 5ms/step - loss: -517778178048.0000 - accuracy: 0.3442 - val_loss: -611505799168.0000 - val_accuracy: 0.3418\n","Epoch 20/200\n","375/375 [==============================] - 2s 5ms/step - loss: -611007135744.0000 - accuracy: 0.3440 - val_loss: -718998208512.0000 - val_accuracy: 0.3418\n","Epoch 21/200\n","375/375 [==============================] - 2s 7ms/step - loss: -715476828160.0000 - accuracy: 0.3441 - val_loss: -838550159360.0000 - val_accuracy: 0.3418\n","Epoch 22/200\n","375/375 [==============================] - 2s 6ms/step - loss: -831461130240.0000 - accuracy: 0.3443 - val_loss: -970155098112.0000 - val_accuracy: 0.3418\n","Epoch 23/200\n","375/375 [==============================] - 2s 5ms/step - loss: -959623659520.0000 - accuracy: 0.3441 - val_loss: -1116985753600.0000 - val_accuracy: 0.3418\n","Epoch 24/200\n","375/375 [==============================] - 2s 5ms/step - loss: -1100614205440.0000 - accuracy: 0.3446 - val_loss: -1275809890304.0000 - val_accuracy: 0.3418\n","Epoch 25/200\n","375/375 [==============================] - 2s 5ms/step - loss: -1255114670080.0000 - accuracy: 0.3442 - val_loss: -1452058869760.0000 - val_accuracy: 0.3418\n","Epoch 26/200\n","375/375 [==============================] - 2s 5ms/step - loss: -1423266676736.0000 - accuracy: 0.3442 - val_loss: -1645465829376.0000 - val_accuracy: 0.3415\n","Epoch 27/200\n","375/375 [==============================] - 2s 5ms/step - loss: -1605520850944.0000 - accuracy: 0.3438 - val_loss: -1849435095040.0000 - val_accuracy: 0.3418\n","Epoch 28/200\n","375/375 [==============================] - 3s 8ms/step - loss: -1804320636928.0000 - accuracy: 0.3440 - val_loss: -2071975559168.0000 - val_accuracy: 0.3418\n","Epoch 29/200\n","375/375 [==============================] - 2s 6ms/step - loss: -2019762634752.0000 - accuracy: 0.3442 - val_loss: -2316575703040.0000 - val_accuracy: 0.3418\n","Epoch 30/200\n","375/375 [==============================] - 2s 5ms/step - loss: -2252525010944.0000 - accuracy: 0.3443 - val_loss: -2579656343552.0000 - val_accuracy: 0.3418\n","Epoch 31/200\n","375/375 [==============================] - 2s 5ms/step - loss: -2502509461504.0000 - accuracy: 0.3443 - val_loss: -2859983175680.0000 - val_accuracy: 0.3418\n","Epoch 32/200\n","375/375 [==============================] - 2s 5ms/step - loss: -2771885490176.0000 - accuracy: 0.3441 - val_loss: -3163388641280.0000 - val_accuracy: 0.3418\n","Epoch 33/200\n","375/375 [==============================] - 2s 6ms/step - loss: -3058501943296.0000 - accuracy: 0.3442 - val_loss: -3482492600320.0000 - val_accuracy: 0.3418\n","Epoch 34/200\n","375/375 [==============================] - 2s 6ms/step - loss: -3365533384704.0000 - accuracy: 0.3440 - val_loss: -3831605755904.0000 - val_accuracy: 0.3418\n","Epoch 35/200\n","375/375 [==============================] - 3s 7ms/step - loss: -3694571552768.0000 - accuracy: 0.3440 - val_loss: -4199239385088.0000 - val_accuracy: 0.3418\n","Epoch 36/200\n","375/375 [==============================] - 2s 5ms/step - loss: -4045378158592.0000 - accuracy: 0.3441 - val_loss: -4590878588928.0000 - val_accuracy: 0.3418\n","Epoch 37/200\n","375/375 [==============================] - 2s 5ms/step - loss: -4418169733120.0000 - accuracy: 0.3442 - val_loss: -5015383572480.0000 - val_accuracy: 0.3418\n","Epoch 38/200\n","375/375 [==============================] - 2s 5ms/step - loss: -4817757405184.0000 - accuracy: 0.3442 - val_loss: -5456249487360.0000 - val_accuracy: 0.3418\n","Epoch 39/200\n","375/375 [==============================] - 2s 5ms/step - loss: -5242827046912.0000 - accuracy: 0.3442 - val_loss: -5935844032512.0000 - val_accuracy: 0.3418\n","Epoch 40/200\n","375/375 [==============================] - 2s 5ms/step - loss: -5695217860608.0000 - accuracy: 0.3441 - val_loss: -6438777782272.0000 - val_accuracy: 0.3418\n","Epoch 41/200\n","375/375 [==============================] - 2s 6ms/step - loss: -6174772035584.0000 - accuracy: 0.3441 - val_loss: -6978936504320.0000 - val_accuracy: 0.3418\n","Epoch 42/200\n","375/375 [==============================] - 2s 7ms/step - loss: -6684174450688.0000 - accuracy: 0.3442 - val_loss: -7547592376320.0000 - val_accuracy: 0.3418\n","Epoch 43/200\n","375/375 [==============================] - 2s 6ms/step - loss: -7223786340352.0000 - accuracy: 0.3443 - val_loss: -8148107132928.0000 - val_accuracy: 0.3418\n","Epoch 44/200\n","375/375 [==============================] - 2s 5ms/step - loss: -7797590196224.0000 - accuracy: 0.3443 - val_loss: -8791939088384.0000 - val_accuracy: 0.3418\n","Epoch 45/200\n","375/375 [==============================] - 2s 5ms/step - loss: -8402486951936.0000 - accuracy: 0.3441 - val_loss: -9464409227264.0000 - val_accuracy: 0.3418\n","Epoch 46/200\n","375/375 [==============================] - 2s 5ms/step - loss: -9036784205824.0000 - accuracy: 0.3442 - val_loss: -10167183736832.0000 - val_accuracy: 0.3418\n","Epoch 47/200\n","375/375 [==============================] - 2s 5ms/step - loss: -9699777839104.0000 - accuracy: 0.3441 - val_loss: -10908226027520.0000 - val_accuracy: 0.3418\n","Epoch 48/200\n","375/375 [==============================] - 2s 7ms/step - loss: -10398613897216.0000 - accuracy: 0.3440 - val_loss: -11689997107200.0000 - val_accuracy: 0.3418\n","Epoch 49/200\n","375/375 [==============================] - 2s 6ms/step - loss: -11135656919040.0000 - accuracy: 0.3441 - val_loss: -12507571814400.0000 - val_accuracy: 0.3418\n","Epoch 50/200\n","375/375 [==============================] - 2s 5ms/step - loss: -11908517199872.0000 - accuracy: 0.3441 - val_loss: -13364513210368.0000 - val_accuracy: 0.3418\n","Epoch 51/200\n","375/375 [==============================] - 2s 5ms/step - loss: -12718800109568.0000 - accuracy: 0.3444 - val_loss: -14256727654400.0000 - val_accuracy: 0.3418\n","Epoch 52/200\n","375/375 [==============================] - 2s 5ms/step - loss: -13560504647680.0000 - accuracy: 0.3441 - val_loss: -15191126310912.0000 - val_accuracy: 0.3418\n","Epoch 53/200\n","375/375 [==============================] - 2s 5ms/step - loss: -14439691583488.0000 - accuracy: 0.3442 - val_loss: -16171764023296.0000 - val_accuracy: 0.3418\n","Epoch 54/200\n","375/375 [==============================] - 2s 7ms/step - loss: -15365022154752.0000 - accuracy: 0.3442 - val_loss: -17198067220480.0000 - val_accuracy: 0.3418\n","Epoch 55/200\n","375/375 [==============================] - 2s 6ms/step - loss: -16334249263104.0000 - accuracy: 0.3442 - val_loss: -18280783806464.0000 - val_accuracy: 0.3418\n","Epoch 56/200\n","375/375 [==============================] - 2s 5ms/step - loss: -17347965353984.0000 - accuracy: 0.3443 - val_loss: -19395642392576.0000 - val_accuracy: 0.3418\n","Epoch 57/200\n","375/375 [==============================] - 2s 5ms/step - loss: -18405874728960.0000 - accuracy: 0.3441 - val_loss: -20578853453824.0000 - val_accuracy: 0.3418\n","Epoch 58/200\n","375/375 [==============================] - 2s 6ms/step - loss: -19510811688960.0000 - accuracy: 0.3442 - val_loss: -21801327394816.0000 - val_accuracy: 0.3418\n","Epoch 59/200\n","375/375 [==============================] - 2s 6ms/step - loss: -20665826541568.0000 - accuracy: 0.3441 - val_loss: -23092522909696.0000 - val_accuracy: 0.3418\n","Epoch 60/200\n","375/375 [==============================] - 2s 5ms/step - loss: -21873542823936.0000 - accuracy: 0.3442 - val_loss: -24427595038720.0000 - val_accuracy: 0.3418\n","Epoch 61/200\n","375/375 [==============================] - 2s 7ms/step - loss: -23133553688576.0000 - accuracy: 0.3442 - val_loss: -25826349285376.0000 - val_accuracy: 0.3418\n","Epoch 62/200\n","375/375 [==============================] - 2s 6ms/step - loss: -24441975209984.0000 - accuracy: 0.3442 - val_loss: -27262084710400.0000 - val_accuracy: 0.3418\n","Epoch 63/200\n","375/375 [==============================] - 2s 5ms/step - loss: -25798144688128.0000 - accuracy: 0.3442 - val_loss: -28759296049152.0000 - val_accuracy: 0.3418\n","Epoch 64/200\n","375/375 [==============================] - 2s 5ms/step - loss: -27203381231616.0000 - accuracy: 0.3442 - val_loss: -30314162290688.0000 - val_accuracy: 0.3418\n","Epoch 65/200\n","375/375 [==============================] - 2s 5ms/step - loss: -28660400652288.0000 - accuracy: 0.3441 - val_loss: -31937336967168.0000 - val_accuracy: 0.3418\n","Epoch 66/200\n","375/375 [==============================] - 2s 5ms/step - loss: -30170306052096.0000 - accuracy: 0.3443 - val_loss: -33592598069248.0000 - val_accuracy: 0.3418\n","Epoch 67/200\n","375/375 [==============================] - 2s 6ms/step - loss: -31733248425984.0000 - accuracy: 0.3442 - val_loss: -35330581331968.0000 - val_accuracy: 0.3418\n","Epoch 68/200\n","375/375 [==============================] - 3s 7ms/step - loss: -33358530740224.0000 - accuracy: 0.3441 - val_loss: -37140327038976.0000 - val_accuracy: 0.3418\n","Epoch 69/200\n","375/375 [==============================] - 2s 5ms/step - loss: -35054745026560.0000 - accuracy: 0.3442 - val_loss: -39012710481920.0000 - val_accuracy: 0.3418\n","Epoch 70/200\n","375/375 [==============================] - 2s 5ms/step - loss: -36819286622208.0000 - accuracy: 0.3442 - val_loss: -40960373293056.0000 - val_accuracy: 0.3418\n","Epoch 71/200\n","375/375 [==============================] - 2s 5ms/step - loss: -38635256676352.0000 - accuracy: 0.3441 - val_loss: -42948569858048.0000 - val_accuracy: 0.3418\n","Epoch 72/200\n","375/375 [==============================] - 2s 5ms/step - loss: -40515936452608.0000 - accuracy: 0.3443 - val_loss: -45035915575296.0000 - val_accuracy: 0.3418\n","Epoch 73/200\n","375/375 [==============================] - 2s 5ms/step - loss: -42468162666496.0000 - accuracy: 0.3441 - val_loss: -47198167367680.0000 - val_accuracy: 0.3418\n","Epoch 74/200\n","375/375 [==============================] - 3s 7ms/step - loss: -44478203166720.0000 - accuracy: 0.3443 - val_loss: -49419491737600.0000 - val_accuracy: 0.3418\n","Epoch 75/200\n","375/375 [==============================] - 2s 6ms/step - loss: -46558405984256.0000 - accuracy: 0.3442 - val_loss: -51713360789504.0000 - val_accuracy: 0.3418\n","Epoch 76/200\n","375/375 [==============================] - 2s 5ms/step - loss: -48727851008000.0000 - accuracy: 0.3443 - val_loss: -54103937908736.0000 - val_accuracy: 0.3418\n","Epoch 77/200\n","375/375 [==============================] - 2s 5ms/step - loss: -50980758487040.0000 - accuracy: 0.3443 - val_loss: -56592913399808.0000 - val_accuracy: 0.3418\n","Epoch 78/200\n","375/375 [==============================] - 2s 5ms/step - loss: -53310576918528.0000 - accuracy: 0.3442 - val_loss: -59174838861824.0000 - val_accuracy: 0.3418\n","Epoch 79/200\n","375/375 [==============================] - 2s 5ms/step - loss: -55708724756480.0000 - accuracy: 0.3442 - val_loss: -61820735848448.0000 - val_accuracy: 0.3418\n","Epoch 80/200\n","375/375 [==============================] - 2s 5ms/step - loss: -58187130601472.0000 - accuracy: 0.3443 - val_loss: -64537071976448.0000 - val_accuracy: 0.3418\n","Epoch 81/200\n","375/375 [==============================] - 3s 7ms/step - loss: -60737154187264.0000 - accuracy: 0.3442 - val_loss: -67363068182528.0000 - val_accuracy: 0.3418\n","Epoch 82/200\n","375/375 [==============================] - 3s 8ms/step - loss: -63359001034752.0000 - accuracy: 0.3442 - val_loss: -70235877015552.0000 - val_accuracy: 0.3418\n","Epoch 83/200\n","375/375 [==============================] - 2s 6ms/step - loss: -66055753957376.0000 - accuracy: 0.3443 - val_loss: -73224805154816.0000 - val_accuracy: 0.3418\n","Epoch 84/200\n","375/375 [==============================] - 2s 5ms/step - loss: -68841568731136.0000 - accuracy: 0.3442 - val_loss: -76295631273984.0000 - val_accuracy: 0.3418\n","Epoch 85/200\n","375/375 [==============================] - 2s 5ms/step - loss: -71710527193088.0000 - accuracy: 0.3442 - val_loss: -79447071916032.0000 - val_accuracy: 0.3418\n","Epoch 86/200\n","375/375 [==============================] - 2s 5ms/step - loss: -74665666019328.0000 - accuracy: 0.3443 - val_loss: -82690367815680.0000 - val_accuracy: 0.3418\n","Epoch 87/200\n","375/375 [==============================] - 2s 6ms/step - loss: -77703155810304.0000 - accuracy: 0.3440 - val_loss: -86052505124864.0000 - val_accuracy: 0.3418\n","Epoch 88/200\n","375/375 [==============================] - 3s 7ms/step - loss: -80828172337152.0000 - accuracy: 0.3443 - val_loss: -89502294999040.0000 - val_accuracy: 0.3418\n","Epoch 89/200\n","375/375 [==============================] - 2s 5ms/step - loss: -84047812362240.0000 - accuracy: 0.3442 - val_loss: -93031239778304.0000 - val_accuracy: 0.3418\n","Epoch 90/200\n","375/375 [==============================] - 2s 5ms/step - loss: -87348444397568.0000 - accuracy: 0.3442 - val_loss: -96652408913920.0000 - val_accuracy: 0.3418\n","Epoch 91/200\n","375/375 [==============================] - 2s 5ms/step - loss: -90742777184256.0000 - accuracy: 0.3441 - val_loss: -100403769245696.0000 - val_accuracy: 0.3418\n","Epoch 92/200\n","375/375 [==============================] - 2s 5ms/step - loss: -94221180600320.0000 - accuracy: 0.3442 - val_loss: -104214185377792.0000 - val_accuracy: 0.3418\n","Epoch 93/200\n","375/375 [==============================] - 2s 6ms/step - loss: -97786750042112.0000 - accuracy: 0.3442 - val_loss: -108143862349824.0000 - val_accuracy: 0.3418\n","Epoch 94/200\n","375/375 [==============================] - 2s 7ms/step - loss: -101457655234560.0000 - accuracy: 0.3443 - val_loss: -112181509095424.0000 - val_accuracy: 0.3418\n","Epoch 95/200\n","375/375 [==============================] - 2s 5ms/step - loss: -105243064926208.0000 - accuracy: 0.3443 - val_loss: -116323644342272.0000 - val_accuracy: 0.3418\n","Epoch 96/200\n","375/375 [==============================] - 2s 5ms/step - loss: -109105607868416.0000 - accuracy: 0.3443 - val_loss: -120592992829440.0000 - val_accuracy: 0.3418\n","Epoch 97/200\n","375/375 [==============================] - 2s 5ms/step - loss: -113060056399872.0000 - accuracy: 0.3442 - val_loss: -124939650727936.0000 - val_accuracy: 0.3418\n","Epoch 98/200\n","375/375 [==============================] - 2s 5ms/step - loss: -117141474902016.0000 - accuracy: 0.3442 - val_loss: -129440340246528.0000 - val_accuracy: 0.3418\n","Epoch 99/200\n","375/375 [==============================] - 2s 5ms/step - loss: -121351750811648.0000 - accuracy: 0.3442 - val_loss: -134056834498560.0000 - val_accuracy: 0.3418\n","Epoch 100/200\n","375/375 [==============================] - 2s 6ms/step - loss: -125683376324608.0000 - accuracy: 0.3442 - val_loss: -138841646170112.0000 - val_accuracy: 0.3418\n","Epoch 101/200\n","375/375 [==============================] - 2s 6ms/step - loss: -130139614609408.0000 - accuracy: 0.3443 - val_loss: -143765322858496.0000 - val_accuracy: 0.3418\n","Epoch 102/200\n","375/375 [==============================] - 2s 5ms/step - loss: -134706481856512.0000 - accuracy: 0.3442 - val_loss: -148767416254464.0000 - val_accuracy: 0.3418\n","Epoch 103/200\n","375/375 [==============================] - 2s 6ms/step - loss: -139366454263808.0000 - accuracy: 0.3442 - val_loss: -153872521756672.0000 - val_accuracy: 0.3418\n","Epoch 104/200\n","375/375 [==============================] - 2s 5ms/step - loss: -144146803195904.0000 - accuracy: 0.3443 - val_loss: -159116425166848.0000 - val_accuracy: 0.3418\n","Epoch 105/200\n","375/375 [==============================] - 2s 5ms/step - loss: -149051840397312.0000 - accuracy: 0.3442 - val_loss: -164528989929472.0000 - val_accuracy: 0.3418\n","Epoch 106/200\n","375/375 [==============================] - 2s 6ms/step - loss: -154079787483136.0000 - accuracy: 0.3441 - val_loss: -170063256616960.0000 - val_accuracy: 0.3418\n","Epoch 107/200\n","375/375 [==============================] - 2s 7ms/step - loss: -159241834856448.0000 - accuracy: 0.3441 - val_loss: -175732630224896.0000 - val_accuracy: 0.3418\n","Epoch 108/200\n","375/375 [==============================] - 2s 5ms/step - loss: -164528939597824.0000 - accuracy: 0.3441 - val_loss: -181505888354304.0000 - val_accuracy: 0.3418\n","Epoch 109/200\n","375/375 [==============================] - 2s 5ms/step - loss: -169943148527616.0000 - accuracy: 0.3441 - val_loss: -187466581540864.0000 - val_accuracy: 0.3418\n","Epoch 110/200\n","375/375 [==============================] - 2s 5ms/step - loss: -175528233402368.0000 - accuracy: 0.3442 - val_loss: -193677808893952.0000 - val_accuracy: 0.3417\n","Epoch 111/200\n","375/375 [==============================] - 2s 5ms/step - loss: -181259531714560.0000 - accuracy: 0.3442 - val_loss: -199940139646976.0000 - val_accuracy: 0.3417\n","Epoch 112/200\n","375/375 [==============================] - 2s 5ms/step - loss: -187096643928064.0000 - accuracy: 0.3442 - val_loss: -206367910526976.0000 - val_accuracy: 0.3417\n","Epoch 113/200\n","375/375 [==============================] - 3s 7ms/step - loss: -193049619595264.0000 - accuracy: 0.3442 - val_loss: -212871564754944.0000 - val_accuracy: 0.3417\n","Epoch 114/200\n","375/375 [==============================] - 2s 6ms/step - loss: -199128457936896.0000 - accuracy: 0.3442 - val_loss: -219544685641728.0000 - val_accuracy: 0.3417\n","Epoch 115/200\n","375/375 [==============================] - 2s 5ms/step - loss: -205365773860864.0000 - accuracy: 0.3443 - val_loss: -226381015285760.0000 - val_accuracy: 0.3417\n","Epoch 116/200\n","375/375 [==============================] - 2s 5ms/step - loss: -211779737092096.0000 - accuracy: 0.3441 - val_loss: -233477727322112.0000 - val_accuracy: 0.3417\n","Epoch 117/200\n","375/375 [==============================] - 2s 5ms/step - loss: -218311879032832.0000 - accuracy: 0.3443 - val_loss: -240579556409344.0000 - val_accuracy: 0.3417\n","Epoch 118/200\n","375/375 [==============================] - 2s 6ms/step - loss: -224974631600128.0000 - accuracy: 0.3441 - val_loss: -247904388251648.0000 - val_accuracy: 0.3417\n","Epoch 119/200\n","375/375 [==============================] - 3s 7ms/step - loss: -231755613208576.0000 - accuracy: 0.3442 - val_loss: -255332366417920.0000 - val_accuracy: 0.3417\n","Epoch 120/200\n","375/375 [==============================] - 2s 6ms/step - loss: -238651468414976.0000 - accuracy: 0.3441 - val_loss: -262883673899008.0000 - val_accuracy: 0.3417\n","Epoch 121/200\n","375/375 [==============================] - 2s 5ms/step - loss: -245708384894976.0000 - accuracy: 0.3442 - val_loss: -270630201065472.0000 - val_accuracy: 0.3417\n","Epoch 122/200\n","375/375 [==============================] - 2s 5ms/step - loss: -252966107873280.0000 - accuracy: 0.3442 - val_loss: -278593523417088.0000 - val_accuracy: 0.3417\n","Epoch 123/200\n","375/375 [==============================] - 2s 5ms/step - loss: -260404320141312.0000 - accuracy: 0.3441 - val_loss: -286806977282048.0000 - val_accuracy: 0.3417\n","Epoch 124/200\n","375/375 [==============================] - 2s 5ms/step - loss: -268013592903680.0000 - accuracy: 0.3442 - val_loss: -295178606739456.0000 - val_accuracy: 0.3417\n","Epoch 125/200\n","375/375 [==============================] - 2s 6ms/step - loss: -275792030334976.0000 - accuracy: 0.3442 - val_loss: -303667844481024.0000 - val_accuracy: 0.3417\n","Epoch 126/200\n","375/375 [==============================] - 2s 6ms/step - loss: -283683059662848.0000 - accuracy: 0.3441 - val_loss: -312332370575360.0000 - val_accuracy: 0.3417\n","Epoch 127/200\n","375/375 [==============================] - 2s 6ms/step - loss: -291708843589632.0000 - accuracy: 0.3442 - val_loss: -321059979001856.0000 - val_accuracy: 0.3417\n","Epoch 128/200\n","375/375 [==============================] - 2s 5ms/step - loss: -299868442591232.0000 - accuracy: 0.3441 - val_loss: -330016663535616.0000 - val_accuracy: 0.3417\n","Epoch 129/200\n","375/375 [==============================] - 2s 5ms/step - loss: -308246648717312.0000 - accuracy: 0.3442 - val_loss: -339225375408128.0000 - val_accuracy: 0.3417\n","Epoch 130/200\n","375/375 [==============================] - 2s 5ms/step - loss: -316811249713152.0000 - accuracy: 0.3442 - val_loss: -348701750984704.0000 - val_accuracy: 0.3417\n","Epoch 131/200\n","375/375 [==============================] - 2s 5ms/step - loss: -325566708318208.0000 - accuracy: 0.3442 - val_loss: -358304760987648.0000 - val_accuracy: 0.3417\n","Epoch 132/200\n","375/375 [==============================] - 2s 6ms/step - loss: -334502253559808.0000 - accuracy: 0.3441 - val_loss: -368090273546240.0000 - val_accuracy: 0.3417\n","Epoch 133/200\n","375/375 [==============================] - 3s 7ms/step - loss: -343623690354688.0000 - accuracy: 0.3443 - val_loss: -378123820466176.0000 - val_accuracy: 0.3417\n","Epoch 134/200\n","375/375 [==============================] - 2s 6ms/step - loss: -352995074113536.0000 - accuracy: 0.3443 - val_loss: -388349399400448.0000 - val_accuracy: 0.3417\n","Epoch 135/200\n","375/375 [==============================] - 2s 5ms/step - loss: -362533189844992.0000 - accuracy: 0.3440 - val_loss: -398822844923904.0000 - val_accuracy: 0.3417\n","Epoch 136/200\n","375/375 [==============================] - 2s 5ms/step - loss: -372284409774080.0000 - accuracy: 0.3442 - val_loss: -409550498824192.0000 - val_accuracy: 0.3417\n","Epoch 137/200\n","375/375 [==============================] - 2s 5ms/step - loss: -382221655474176.0000 - accuracy: 0.3443 - val_loss: -420441327927296.0000 - val_accuracy: 0.3415\n","Epoch 138/200\n","375/375 [==============================] - 2s 5ms/step - loss: -392333786873856.0000 - accuracy: 0.3442 - val_loss: -431436913967104.0000 - val_accuracy: 0.3417\n","Epoch 139/200\n","375/375 [==============================] - 3s 7ms/step - loss: -402606207795200.0000 - accuracy: 0.3442 - val_loss: -442748079439872.0000 - val_accuracy: 0.3417\n","Epoch 140/200\n","375/375 [==============================] - 2s 6ms/step - loss: -413010732515328.0000 - accuracy: 0.3441 - val_loss: -454058942922752.0000 - val_accuracy: 0.3417\n","Epoch 141/200\n","375/375 [==============================] - 2s 5ms/step - loss: -423650842902528.0000 - accuracy: 0.3442 - val_loss: -465814067085312.0000 - val_accuracy: 0.3417\n","Epoch 142/200\n","375/375 [==============================] - 2s 5ms/step - loss: -434496440631296.0000 - accuracy: 0.3442 - val_loss: -477573821759488.0000 - val_accuracy: 0.3417\n","Epoch 143/200\n","375/375 [==============================] - 2s 5ms/step - loss: -445564403580928.0000 - accuracy: 0.3442 - val_loss: -489835349409792.0000 - val_accuracy: 0.3417\n","Epoch 144/200\n","375/375 [==============================] - 2s 5ms/step - loss: -456848826171392.0000 - accuracy: 0.3442 - val_loss: -502133954707456.0000 - val_accuracy: 0.3417\n","Epoch 145/200\n","375/375 [==============================] - 3s 7ms/step - loss: -468335145779200.0000 - accuracy: 0.3442 - val_loss: -514714886995968.0000 - val_accuracy: 0.3417\n","Epoch 146/200\n","375/375 [==============================] - 2s 6ms/step - loss: -480021248475136.0000 - accuracy: 0.3442 - val_loss: -527678172037120.0000 - val_accuracy: 0.3415\n","Epoch 147/200\n","375/375 [==============================] - 2s 5ms/step - loss: -491965955178496.0000 - accuracy: 0.3441 - val_loss: -540701553065984.0000 - val_accuracy: 0.3417\n","Epoch 148/200\n","375/375 [==============================] - 2s 6ms/step - loss: -504096989642752.0000 - accuracy: 0.3441 - val_loss: -554066920865792.0000 - val_accuracy: 0.3415\n","Epoch 149/200\n","375/375 [==============================] - 2s 6ms/step - loss: -516411231305728.0000 - accuracy: 0.3441 - val_loss: -567454367481856.0000 - val_accuracy: 0.3415\n","Epoch 150/200\n","375/375 [==============================] - 2s 5ms/step - loss: -528941362184192.0000 - accuracy: 0.3442 - val_loss: -580994184773632.0000 - val_accuracy: 0.3417\n","Epoch 151/200\n","375/375 [==============================] - 2s 6ms/step - loss: -541707649155072.0000 - accuracy: 0.3442 - val_loss: -595073423114240.0000 - val_accuracy: 0.3415\n","Epoch 152/200\n","375/375 [==============================] - 3s 7ms/step - loss: -554707105873920.0000 - accuracy: 0.3443 - val_loss: -609335935762432.0000 - val_accuracy: 0.3415\n","Epoch 153/200\n","375/375 [==============================] - 2s 6ms/step - loss: -567978286383104.0000 - accuracy: 0.3442 - val_loss: -623858696585216.0000 - val_accuracy: 0.3417\n","Epoch 154/200\n","375/375 [==============================] - 2s 5ms/step - loss: -581374222270464.0000 - accuracy: 0.3442 - val_loss: -638460444540928.0000 - val_accuracy: 0.3417\n","Epoch 155/200\n","375/375 [==============================] - 2s 5ms/step - loss: -594975846825984.0000 - accuracy: 0.3442 - val_loss: -653420218286080.0000 - val_accuracy: 0.3417\n","Epoch 156/200\n","375/375 [==============================] - 2s 5ms/step - loss: -608803158491136.0000 - accuracy: 0.3443 - val_loss: -668595948355584.0000 - val_accuracy: 0.3415\n","Epoch 157/200\n","375/375 [==============================] - 2s 5ms/step - loss: -622873337135104.0000 - accuracy: 0.3442 - val_loss: -683778926182400.0000 - val_accuracy: 0.3417\n","Epoch 158/200\n","375/375 [==============================] - 3s 7ms/step - loss: -637111422156800.0000 - accuracy: 0.3442 - val_loss: -699495285260288.0000 - val_accuracy: 0.3417\n","Epoch 159/200\n","375/375 [==============================] - 2s 6ms/step - loss: -651588213407744.0000 - accuracy: 0.3442 - val_loss: -715187216711680.0000 - val_accuracy: 0.3417\n","Epoch 160/200\n","375/375 [==============================] - 2s 5ms/step - loss: -666331762393088.0000 - accuracy: 0.3442 - val_loss: -731444070580224.0000 - val_accuracy: 0.3417\n","Epoch 161/200\n","375/375 [==============================] - 2s 5ms/step - loss: -681405486989312.0000 - accuracy: 0.3442 - val_loss: -747962313474048.0000 - val_accuracy: 0.3417\n","Epoch 162/200\n","375/375 [==============================] - 2s 5ms/step - loss: -696749458980864.0000 - accuracy: 0.3442 - val_loss: -764699129937920.0000 - val_accuracy: 0.3417\n","Epoch 163/200\n","375/375 [==============================] - 2s 6ms/step - loss: -712386092728320.0000 - accuracy: 0.3442 - val_loss: -781949329211392.0000 - val_accuracy: 0.3417\n","Epoch 164/200\n","375/375 [==============================] - 2s 6ms/step - loss: -728282571997184.0000 - accuracy: 0.3442 - val_loss: -799248115302400.0000 - val_accuracy: 0.3417\n","Epoch 165/200\n","375/375 [==============================] - 3s 7ms/step - loss: -744427219845120.0000 - accuracy: 0.3442 - val_loss: -816933851103232.0000 - val_accuracy: 0.3417\n","Epoch 166/200\n","375/375 [==============================] - 2s 5ms/step - loss: -760773529829376.0000 - accuracy: 0.3442 - val_loss: -834841650135040.0000 - val_accuracy: 0.3417\n","Epoch 167/200\n","375/375 [==============================] - 2s 5ms/step - loss: -777436660760576.0000 - accuracy: 0.3442 - val_loss: -853177872154624.0000 - val_accuracy: 0.3417\n","Epoch 168/200\n","375/375 [==============================] - 2s 5ms/step - loss: -794325613019136.0000 - accuracy: 0.3442 - val_loss: -871685691539456.0000 - val_accuracy: 0.3415\n","Epoch 169/200\n","375/375 [==============================] - 2s 5ms/step - loss: -811500784582656.0000 - accuracy: 0.3443 - val_loss: -890346519134208.0000 - val_accuracy: 0.3415\n","Epoch 170/200\n","375/375 [==============================] - 2s 6ms/step - loss: -828858693582848.0000 - accuracy: 0.3442 - val_loss: -909277795450880.0000 - val_accuracy: 0.3417\n","Epoch 171/200\n","375/375 [==============================] - 2s 7ms/step - loss: -846467119972352.0000 - accuracy: 0.3442 - val_loss: -928744264957952.0000 - val_accuracy: 0.3415\n","Epoch 172/200\n","375/375 [==============================] - 2s 6ms/step - loss: -864382233870336.0000 - accuracy: 0.3442 - val_loss: -948134096142336.0000 - val_accuracy: 0.3417\n","Epoch 173/200\n","375/375 [==============================] - 2s 5ms/step - loss: -882569541320704.0000 - accuracy: 0.3442 - val_loss: -968218973831168.0000 - val_accuracy: 0.3415\n","Epoch 174/200\n","375/375 [==============================] - 2s 5ms/step - loss: -901151516000256.0000 - accuracy: 0.3442 - val_loss: -988347405172736.0000 - val_accuracy: 0.3415\n","Epoch 175/200\n","375/375 [==============================] - 2s 5ms/step - loss: -920069102108672.0000 - accuracy: 0.3442 - val_loss: -1009189740609536.0000 - val_accuracy: 0.3415\n","Epoch 176/200\n","375/375 [==============================] - 2s 5ms/step - loss: -939360551698432.0000 - accuracy: 0.3441 - val_loss: -1030174481055744.0000 - val_accuracy: 0.3415\n","Epoch 177/200\n","375/375 [==============================] - 3s 7ms/step - loss: -958872453906432.0000 - accuracy: 0.3442 - val_loss: -1051478257041408.0000 - val_accuracy: 0.3415\n","Epoch 178/200\n","375/375 [==============================] - 3s 7ms/step - loss: -978611788054528.0000 - accuracy: 0.3442 - val_loss: -1073112342855680.0000 - val_accuracy: 0.3415\n","Epoch 179/200\n","375/375 [==============================] - 2s 6ms/step - loss: -998610363744256.0000 - accuracy: 0.3442 - val_loss: -1095075194994688.0000 - val_accuracy: 0.3415\n","Epoch 180/200\n","375/375 [==============================] - 2s 5ms/step - loss: -1019011324182528.0000 - accuracy: 0.3442 - val_loss: -1117346882125824.0000 - val_accuracy: 0.3415\n","Epoch 181/200\n","375/375 [==============================] - 2s 5ms/step - loss: -1039676223782912.0000 - accuracy: 0.3443 - val_loss: -1139953710923776.0000 - val_accuracy: 0.3415\n","Epoch 182/200\n","375/375 [==============================] - 2s 5ms/step - loss: -1060539497185280.0000 - accuracy: 0.3442 - val_loss: -1162905479282688.0000 - val_accuracy: 0.3415\n","Epoch 183/200\n","375/375 [==============================] - 2s 5ms/step - loss: -1081659797536768.0000 - accuracy: 0.3441 - val_loss: -1185783025238016.0000 - val_accuracy: 0.3415\n","Epoch 184/200\n","375/375 [==============================] - 2s 7ms/step - loss: -1103056116645888.0000 - accuracy: 0.3442 - val_loss: -1209176369922048.0000 - val_accuracy: 0.3415\n","Epoch 185/200\n","375/375 [==============================] - 2s 6ms/step - loss: -1124766303911936.0000 - accuracy: 0.3442 - val_loss: -1232966193774592.0000 - val_accuracy: 0.3415\n","Epoch 186/200\n","375/375 [==============================] - 2s 5ms/step - loss: -1146917597741056.0000 - accuracy: 0.3442 - val_loss: -1257192359460864.0000 - val_accuracy: 0.3415\n","Epoch 187/200\n","375/375 [==============================] - 2s 5ms/step - loss: -1169508320411648.0000 - accuracy: 0.3442 - val_loss: -1281875939164160.0000 - val_accuracy: 0.3415\n","Epoch 188/200\n","375/375 [==============================] - 2s 5ms/step - loss: -1192514715385856.0000 - accuracy: 0.3442 - val_loss: -1307280268066816.0000 - val_accuracy: 0.3415\n","Epoch 189/200\n","375/375 [==============================] - 2s 5ms/step - loss: -1215740153692160.0000 - accuracy: 0.3441 - val_loss: -1332483270377472.0000 - val_accuracy: 0.3415\n","Epoch 190/200\n","375/375 [==============================] - 3s 7ms/step - loss: -1239214700101632.0000 - accuracy: 0.3442 - val_loss: -1358103689822208.0000 - val_accuracy: 0.3415\n","Epoch 191/200\n","375/375 [==============================] - 3s 7ms/step - loss: -1263207729594368.0000 - accuracy: 0.3442 - val_loss: -1384516262297600.0000 - val_accuracy: 0.3415\n","Epoch 192/200\n","375/375 [==============================] - 2s 5ms/step - loss: -1287584219136000.0000 - accuracy: 0.3442 - val_loss: -1411190961995776.0000 - val_accuracy: 0.3415\n","Epoch 193/200\n","375/375 [==============================] - 2s 6ms/step - loss: -1312246592438272.0000 - accuracy: 0.3442 - val_loss: -1437975183360000.0000 - val_accuracy: 0.3415\n","Epoch 194/200\n","375/375 [==============================] - 2s 6ms/step - loss: -1337175924801536.0000 - accuracy: 0.3442 - val_loss: -1465282988081152.0000 - val_accuracy: 0.3415\n","Epoch 195/200\n","375/375 [==============================] - 2s 5ms/step - loss: -1362362418331648.0000 - accuracy: 0.3441 - val_loss: -1492882447925248.0000 - val_accuracy: 0.3415\n","Epoch 196/200\n","375/375 [==============================] - 2s 7ms/step - loss: -1387906870542336.0000 - accuracy: 0.3443 - val_loss: -1520629949923328.0000 - val_accuracy: 0.3415\n","Epoch 197/200\n","375/375 [==============================] - 2s 7ms/step - loss: -1413885517103104.0000 - accuracy: 0.3442 - val_loss: -1549157391138816.0000 - val_accuracy: 0.3415\n","Epoch 198/200\n","375/375 [==============================] - 2s 6ms/step - loss: -1440301981892608.0000 - accuracy: 0.3442 - val_loss: -1578024940077056.0000 - val_accuracy: 0.3415\n","Epoch 199/200\n","375/375 [==============================] - 2s 5ms/step - loss: -1467078821281792.0000 - accuracy: 0.3442 - val_loss: -1607275277975552.0000 - val_accuracy: 0.3415\n","Epoch 200/200\n","375/375 [==============================] - 2s 6ms/step - loss: -1494282338828288.0000 - accuracy: 0.3442 - val_loss: -1636849885904896.0000 - val_accuracy: 0.3415\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f7ca9724e80>"]},"metadata":{},"execution_count":8}]}]}