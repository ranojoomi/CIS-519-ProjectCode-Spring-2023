{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"emG8El09ids3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682364464174,"user_tz":240,"elapsed":1421,"user":{"displayName":"Radin Nojoomi","userId":"08257129610895475884"}},"outputId":"b8491ab1-821a-4a07-c11b-d1ef4948d6e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Read in the data and clean up column names\n","import gensim\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["df = pd.read_csv('../content/drive/MyDrive/Reviews.csv')\n","\n","df = df[['Text','Score']]\n","df['Score'].isnull().sum()\n","df['Score'].isnull().sum()\n","df.drop_duplicates(subset=['Text','Score'],keep='first',inplace=True)\n","\n","def set_sent(score):\n","    if score<=2:\n","        return 0\n","    elif score==3:\n","        return 1\n","    else:\n","        return 2\n","\n","df['sentiment']=df['Score'].apply(set_sent)\n","df = df[['Text','sentiment']]\n","\n","# Separate into three sentiment groups\n","df_neg1 = df[df['sentiment']==0]\n","df_0 = df[df['sentiment']==1]\n","df_1 = df[df['sentiment']==2]\n","\n","n = 15000\n","\n","df_neg1 = df_neg1.sample(n=n, random_state=42, replace=False)\n","df_0 = df_0.sample(n=n, random_state=42, replace=False)\n","df_1 = df_1.sample(n=n, random_state=42, replace=False)\n","# print(\"df_neg1: \", df_neg1)\n","# print(\"df_0: \", df_0)\n","# print(\"df_1: \", df_1)\n","\n","sub_df = pd.concat([df_neg1, df_0, df_1], axis=0)\n","X = sub_df['Text']\n","\n","# Tokenize using gensim\n","X = X.apply(lambda x: gensim.utils.simple_preprocess(x))\n","\n","'''\n","list_of_lists = []\n","\n","for item in X:\n","    my_list = item.split()\n","    list_of_lists.append(my_list)\n","\n","X = pd.Series(list_of_lists)\n","'''\n","\n","y = sub_df['sentiment']"],"metadata":{"id":"Q_gjrOm8kFuL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=0.2)"],"metadata":{"id":"PXSWvLVkivGJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the word2vec model\n","w2v_model = gensim.models.Word2Vec(X_train,\n","                                   vector_size=100,\n","                                   window=5,\n","                                   min_count=2)"],"metadata":{"id":"2l3C69z7i0q4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["w2v_model.wv.index_to_key"],"metadata":{"id":"WVrQumqTi2dH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Find the most similar words to \"king\" based on word vectors from our trained model\n","# w2v_model.wv.most_similar('meat')"],"metadata":{"id":"KYLSudIai2m2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["words = set(w2v_model.wv.index_to_key )\n","X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n","                         for ls in X_train])\n","X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n","                         for ls in X_test])"],"metadata":{"id":"p2SeiwWei2o2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682364512014,"user_tz":240,"elapsed":10612,"user":{"displayName":"Radin Nojoomi","userId":"08257129610895475884"}},"outputId":"e57524a9-de15-4a80-fed9-fc2c35dd987b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-82-b5f4a0d5af08>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n","<ipython-input-82-b5f4a0d5af08>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n"]}]},{"cell_type":"code","source":["# Compute sentence vectors by averaging the word vectors for the words contained in the sentence\n","X_train_vect_avg = []\n","for v in X_train_vect:\n","    if v.size:\n","        X_train_vect_avg.append(v.mean(axis=0))\n","    else:\n","        X_train_vect_avg.append(np.zeros(100, dtype=float))\n","        \n","X_test_vect_avg = []\n","for v in X_test_vect:\n","    if v.size:\n","        X_test_vect_avg.append(v.mean(axis=0))\n","    else:\n","        X_test_vect_avg.append(np.zeros(100, dtype=float))"],"metadata":{"id":"qduJkfsXi28n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instantiate and fit a basic Random Forest model on top of the vectors\n","from sklearn.ensemble import RandomForestClassifier\n","rf = RandomForestClassifier()\n","rf_model = rf.fit(X_train_vect_avg, y_train.values.ravel())"],"metadata":{"id":"42_CnINii29z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use the trained model to make predictions on the test data\n","y_pred = rf_model.predict(X_test_vect_avg)"],"metadata":{"id":"J24YhRuNjHKS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import precision_score, recall_score\n","\n","average = 'micro'\n","\n","precision = precision_score(y_test, y_pred, average=average)\n","recall = recall_score(y_test, y_pred, average=average)\n","print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n","    round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"],"metadata":{"id":"I5dkqgiDjHTD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682364567808,"user_tz":240,"elapsed":8,"user":{"displayName":"Radin Nojoomi","userId":"08257129610895475884"}},"outputId":"78d4dc24-a312-4755-d2d8-b466745dd8f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.599 / Recall: 0.599 / Accuracy: 0.599\n"]}]}]}