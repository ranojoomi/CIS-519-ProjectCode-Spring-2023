{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1tAuW4gWR3bTPFJUFW5DFMCxGOMT-P7Mt","timestamp":1682524392609},{"file_id":"1ZBeMZv4EhQZIPyou09l2fUbfIVn-gLW9","timestamp":1682474034949}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"6Fam410cQUPp","executionInfo":{"status":"ok","timestamp":1682525078454,"user_tz":240,"elapsed":10551,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow\n","from gensim.models.word2vec import Word2Vec\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","from keras.layers import Dense, Dropout, Conv1D, MaxPool1D, GlobalMaxPool1D, Embedding, Activation\n","from keras.preprocessing.text import Tokenizer\n","# from keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem.snowball import PorterStemmer\n","from sklearn import preprocessing\n","import gensim\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","import string\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from gensim.models import Word2Vec\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n","from tensorflow.keras.models import Sequential\n","import nltk"]},{"cell_type":"code","source":["def preprocess_text(sen):\n","    # Remove punctuations and numbers\n","    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n","\n","    # Single character removal\n","    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n","\n","    # Removing multiple spaces\n","    sentence = re.sub(r'\\s+', ' ', sentence)\n","    \n","    stops = stopwords.words('english')\n","    #print(stops)\n","    porter = PorterStemmer()\n","    for word in sentence.split():\n","        if word in stops:\n","            sentence = sentence.replace(word, '')\n","        sentence = sentence.replace(word, porter.stem(word))\n","    return sentence.lower()"],"metadata":{"id":"q5vI_KKRQhi4","executionInfo":{"status":"ok","timestamp":1682525078455,"user_tz":240,"elapsed":46,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","df = pd.read_csv('../content/drive/MyDrive/Reviews.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nfnuWQq1QhlW","executionInfo":{"status":"ok","timestamp":1682525087357,"user_tz":240,"elapsed":8945,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}},"outputId":"8d2efb49-23ab-4efd-e041-d8d7a4cec229"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["\n","df = df[['Text','Score']]\n","df['Score'].isnull().sum()\n","df['Score'].isnull().sum()\n","df.drop_duplicates(subset=['Text','Score'],keep='first',inplace=True)\n","\n","def set_sent(score):\n","    if score<=2:\n","        return 0\n","    elif score>3:\n","        return 1\n","\n","df['sentiment']=df['Score'].apply(set_sent)\n","df = df[['Text','sentiment']]\n","\n","# Separate into three sentiment groups\n","df_neg1 = df[df['sentiment']==0]\n","df_0 = df[df['sentiment']==1]\n","\n","\n","n = 15000\n","\n","df_neg1 = df_neg1.sample(n=n, random_state=42, replace=False)\n","df_0 = df_0.sample(n=n, random_state=42, replace=False)\n","# print(\"df_neg1: \", df_neg1)\n","# print(\"df_0: \", df_0)\n","# print(\"df_1: \", df_1)\n","\n","sub_df = pd.concat([df_neg1, df_0], axis=0)\n","X = sub_df['Text']\n","\n","y = sub_df['sentiment']"],"metadata":{"id":"Do5l28aCRafi","executionInfo":{"status":"ok","timestamp":1682525090976,"user_tz":240,"elapsed":3650,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["mes = []\n","for i in X:\n","    mes.append(i.split())\n","print(mes[:2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ptIxHOUKQhn8","executionInfo":{"status":"ok","timestamp":1682525091124,"user_tz":240,"elapsed":154,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}},"outputId":"339ecbf2-dba0-400e-d0ee-feea555b0592"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[['Vile', 'and', 'revolting', '\"tahini\";', 'absolutely', 'ruined', 'a', 'batch', 'a', 'hummus.', 'This', 'tahini', 'has', 'a', 'bitter,', 'metallic', 'and', 'chemical', 'like', 'taste.', 'It', 'is', 'not', 'a', 'matter', 'of', 'not', 'knowing', 'how', 'to', 'use', 'it', '(it', 'separates,', 'mix', 'it', 'up', 'just', 'like', 'natural', 'peanut', 'butter)', 'it', 'is', 'a', 'matter', 'of', 'an', 'awful', 'product.', 'Stay', 'far,', 'far', 'away', 'and', 'ignore', 'the', '5', 'star', 'reviews', 'which', 'sound', 'suspiciously', 'like', 'they', 'were', 'written', 'by', 'Joyva.', 'There', 'is', 'far', 'better', 'tahini', 'out', 'there.'], ['They', 'will', 'send', 'you', '70%', 'cocoa', 'lindt', 'chocolate', 'but', 'it', 'has', 'a', '\"new', 'recipe\".', \"It's\", '30', 'calories', 'more', 'a', 'serving,', 'all', 'sugar,', 'and', 'takes', 'like', 'crappy', 'milk', 'chocolate', \"you'd\", 'get', 'in', 'a', 'cheap', 'easter', 'bunny.', 'Has', 'none', 'of', 'the', 'cocoa', 'bite', 'that', 'it', 'used', 'to.', 'This', 'is', 'kind', 'of', 'sad,', 'since', 'this', 'chocolate', 'used', 'to', 'be', 'the', 'best', 'readily', 'available', 'dark', 'chocolate', 'on', 'the', 'market.<br', '/><br', '/>If', \"you're\", 'looking', 'for', 'a', 'dark', 'chocolate', \"that's\", 'kind', 'of', 'low', 'in', 'carbs,', 'this', \"isn't\", 'it.', 'Save', 'yourself', 'some', 'money', 'and', 'buy', 'a', 'hersey', 'bar.']]\n"]}]},{"cell_type":"code","source":["w2v_model = Word2Vec(mes, window=10, min_count=1, workers=16)\n","print(w2v_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GhChcFxvQhqO","executionInfo":{"status":"ok","timestamp":1682525118418,"user_tz":240,"elapsed":27297,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}},"outputId":"4f64efa6-78de-4e4a-fd21-37cb1dc4c8b2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Word2Vec<vocab=117883, vector_size=100, alpha=0.025>\n"]}]},{"cell_type":"code","source":["# Preprocess the text data\n","import nltk\n","nltk.download('stopwords')\n","import nltk\n","nltk.download('punkt')\n","stop_words = set(stopwords.words('english'))\n","def preprocess(text):\n","    text = text.lower()\n","    text = ''.join([word for word in text if word not in string.punctuation])\n","    tokens = word_tokenize(text)\n","    tokens = [word for word in tokens if word not in stop_words]\n","    return ' '.join(tokens)\n","\n","X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=0.2)\n","\n","X_train = X_train.apply(preprocess)\n","X_test = X_test.apply(preprocess)\n","\n","max_length = 100\n","\n","# Tokenize the text data\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(X_train)\n","X_train = tokenizer.texts_to_sequences(X_train)\n","X_test = tokenizer.texts_to_sequences(X_test)\n","X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n","X_test = pad_sequences(X_test, maxlen=max_length, padding='post')\n","vocab_size = len(tokenizer.word_index) + 1\n","# Create a weight matrix for the embedding layer\n","embedding_matrix = np.zeros((vocab_size, 100))\n","for word, i in tokenizer.word_index.items():\n","    if word in w2v_model.wv:\n","        embedding_matrix[i] = w2v_model.wv[word]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uugRQEMFQhtf","outputId":"2544fe5f-31f1-478c-b638-e75f7301ac27","executionInfo":{"status":"ok","timestamp":1682525133290,"user_tz":240,"elapsed":14917,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras import layers\n","\n","embedding_dim = 50\n","maxlen = 100\n","\n","model = Sequential()\n","model.add(layers.Embedding(input_dim=vocab_size, \n","                           output_dim=embedding_dim, \n","                           input_length=maxlen))\n","model.add(layers.GlobalMaxPool1D())\n","model.add(layers.Dense(10, activation='relu'))\n","model.add(layers.Dense(32, activation='relu'))\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))\n"],"metadata":{"id":"Flu1HbOLPBNp","executionInfo":{"status":"ok","timestamp":1682525554306,"user_tz":240,"elapsed":421061,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4b1bab6d-4aa5-47b3-aaf6-a492a8ae3176"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","375/375 [==============================] - 77s 191ms/step - loss: 0.4237 - accuracy: 0.7847 - val_loss: 0.3152 - val_accuracy: 0.8655\n","Epoch 2/100\n","375/375 [==============================] - 27s 72ms/step - loss: 0.2312 - accuracy: 0.9066 - val_loss: 0.3277 - val_accuracy: 0.8617\n","Epoch 3/100\n","375/375 [==============================] - 11s 31ms/step - loss: 0.1358 - accuracy: 0.9505 - val_loss: 0.3599 - val_accuracy: 0.8595\n","Epoch 4/100\n","375/375 [==============================] - 9s 24ms/step - loss: 0.0737 - accuracy: 0.9760 - val_loss: 0.4224 - val_accuracy: 0.8557\n","Epoch 5/100\n","375/375 [==============================] - 7s 20ms/step - loss: 0.0383 - accuracy: 0.9881 - val_loss: 0.5549 - val_accuracy: 0.8425\n","Epoch 6/100\n","375/375 [==============================] - 6s 17ms/step - loss: 0.0250 - accuracy: 0.9920 - val_loss: 0.5890 - val_accuracy: 0.8528\n","Epoch 7/100\n","375/375 [==============================] - 5s 14ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.7052 - val_accuracy: 0.8477\n","Epoch 8/100\n","375/375 [==============================] - 5s 14ms/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 0.7165 - val_accuracy: 0.8467\n","Epoch 9/100\n","375/375 [==============================] - 5s 14ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.9378 - val_accuracy: 0.8352\n","Epoch 10/100\n","375/375 [==============================] - 4s 11ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.8760 - val_accuracy: 0.8423\n","Epoch 11/100\n","375/375 [==============================] - 3s 9ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.9522 - val_accuracy: 0.8428\n","Epoch 12/100\n","375/375 [==============================] - 4s 10ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 1.0532 - val_accuracy: 0.8398\n","Epoch 13/100\n","375/375 [==============================] - 5s 13ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.9421 - val_accuracy: 0.8425\n","Epoch 14/100\n","375/375 [==============================] - 4s 10ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.9550 - val_accuracy: 0.8427\n","Epoch 15/100\n","375/375 [==============================] - 4s 10ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 1.0297 - val_accuracy: 0.8410\n","Epoch 16/100\n","375/375 [==============================] - 3s 9ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 1.1016 - val_accuracy: 0.8402\n","Epoch 17/100\n","375/375 [==============================] - 4s 12ms/step - loss: 6.2239e-04 - accuracy: 0.9998 - val_loss: 1.2046 - val_accuracy: 0.8377\n","Epoch 18/100\n","375/375 [==============================] - 5s 13ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 1.2575 - val_accuracy: 0.8438\n","Epoch 19/100\n","375/375 [==============================] - 3s 7ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.9621 - val_accuracy: 0.8385\n","Epoch 20/100\n","375/375 [==============================] - 3s 7ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 1.1747 - val_accuracy: 0.8325\n","Epoch 21/100\n","375/375 [==============================] - 3s 8ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 1.0413 - val_accuracy: 0.8372\n","Epoch 22/100\n","375/375 [==============================] - 4s 12ms/step - loss: 9.5434e-04 - accuracy: 0.9998 - val_loss: 1.3888 - val_accuracy: 0.8220\n","Epoch 23/100\n","375/375 [==============================] - 3s 7ms/step - loss: 5.7085e-04 - accuracy: 0.9998 - val_loss: 1.2203 - val_accuracy: 0.8403\n","Epoch 24/100\n","375/375 [==============================] - 3s 8ms/step - loss: 9.1881e-06 - accuracy: 1.0000 - val_loss: 1.3567 - val_accuracy: 0.8400\n","Epoch 25/100\n","375/375 [==============================] - 3s 7ms/step - loss: 3.1653e-06 - accuracy: 1.0000 - val_loss: 1.4550 - val_accuracy: 0.8398\n","Epoch 26/100\n","375/375 [==============================] - 3s 8ms/step - loss: 1.6010e-06 - accuracy: 1.0000 - val_loss: 1.5291 - val_accuracy: 0.8395\n","Epoch 27/100\n","375/375 [==============================] - 4s 12ms/step - loss: 9.4347e-07 - accuracy: 1.0000 - val_loss: 1.5897 - val_accuracy: 0.8397\n","Epoch 28/100\n","375/375 [==============================] - 3s 9ms/step - loss: 6.0818e-07 - accuracy: 1.0000 - val_loss: 1.6431 - val_accuracy: 0.8397\n","Epoch 29/100\n","375/375 [==============================] - 2s 7ms/step - loss: 4.1577e-07 - accuracy: 1.0000 - val_loss: 1.6900 - val_accuracy: 0.8395\n","Epoch 30/100\n","375/375 [==============================] - 3s 7ms/step - loss: 2.9558e-07 - accuracy: 1.0000 - val_loss: 1.7300 - val_accuracy: 0.8392\n","Epoch 31/100\n","375/375 [==============================] - 4s 11ms/step - loss: 2.1874e-07 - accuracy: 1.0000 - val_loss: 1.7697 - val_accuracy: 0.8390\n","Epoch 32/100\n","375/375 [==============================] - 3s 7ms/step - loss: 1.6427e-07 - accuracy: 1.0000 - val_loss: 1.8050 - val_accuracy: 0.8392\n","Epoch 33/100\n","375/375 [==============================] - 3s 9ms/step - loss: 1.2644e-07 - accuracy: 1.0000 - val_loss: 1.8385 - val_accuracy: 0.8392\n","Epoch 34/100\n","375/375 [==============================] - 2s 6ms/step - loss: 9.8943e-08 - accuracy: 1.0000 - val_loss: 1.8696 - val_accuracy: 0.8393\n","Epoch 35/100\n","375/375 [==============================] - 2s 6ms/step - loss: 7.8525e-08 - accuracy: 1.0000 - val_loss: 1.8992 - val_accuracy: 0.8397\n","Epoch 36/100\n","375/375 [==============================] - 3s 8ms/step - loss: 6.3044e-08 - accuracy: 1.0000 - val_loss: 1.9268 - val_accuracy: 0.8395\n","Epoch 37/100\n","375/375 [==============================] - 3s 8ms/step - loss: 5.1115e-08 - accuracy: 1.0000 - val_loss: 1.9535 - val_accuracy: 0.8395\n","Epoch 38/100\n","375/375 [==============================] - 3s 7ms/step - loss: 4.1747e-08 - accuracy: 1.0000 - val_loss: 1.9798 - val_accuracy: 0.8395\n","Epoch 39/100\n","375/375 [==============================] - 3s 7ms/step - loss: 3.4322e-08 - accuracy: 1.0000 - val_loss: 2.0045 - val_accuracy: 0.8395\n","Epoch 40/100\n","375/375 [==============================] - 3s 8ms/step - loss: 2.8499e-08 - accuracy: 1.0000 - val_loss: 2.0283 - val_accuracy: 0.8395\n","Epoch 41/100\n","375/375 [==============================] - 3s 8ms/step - loss: 2.3784e-08 - accuracy: 1.0000 - val_loss: 2.0509 - val_accuracy: 0.8395\n","Epoch 42/100\n","375/375 [==============================] - 3s 8ms/step - loss: 1.9970e-08 - accuracy: 1.0000 - val_loss: 2.0727 - val_accuracy: 0.8395\n","Epoch 43/100\n","375/375 [==============================] - 3s 8ms/step - loss: 1.6891e-08 - accuracy: 1.0000 - val_loss: 2.0936 - val_accuracy: 0.8395\n","Epoch 44/100\n","375/375 [==============================] - 2s 6ms/step - loss: 1.4354e-08 - accuracy: 1.0000 - val_loss: 2.1139 - val_accuracy: 0.8395\n","Epoch 45/100\n","375/375 [==============================] - 3s 7ms/step - loss: 1.2249e-08 - accuracy: 1.0000 - val_loss: 2.1335 - val_accuracy: 0.8395\n","Epoch 46/100\n","375/375 [==============================] - 4s 10ms/step - loss: 1.0527e-08 - accuracy: 1.0000 - val_loss: 2.1522 - val_accuracy: 0.8397\n","Epoch 47/100\n","375/375 [==============================] - 3s 9ms/step - loss: 9.0502e-09 - accuracy: 1.0000 - val_loss: 2.1700 - val_accuracy: 0.8397\n","Epoch 48/100\n","375/375 [==============================] - 2s 6ms/step - loss: 7.8195e-09 - accuracy: 1.0000 - val_loss: 2.1876 - val_accuracy: 0.8398\n","Epoch 49/100\n","375/375 [==============================] - 2s 6ms/step - loss: 6.7897e-09 - accuracy: 1.0000 - val_loss: 2.2046 - val_accuracy: 0.8398\n","Epoch 50/100\n","375/375 [==============================] - 3s 8ms/step - loss: 5.9041e-09 - accuracy: 1.0000 - val_loss: 2.2208 - val_accuracy: 0.8397\n","Epoch 51/100\n","375/375 [==============================] - 3s 8ms/step - loss: 5.1599e-09 - accuracy: 1.0000 - val_loss: 2.2365 - val_accuracy: 0.8397\n","Epoch 52/100\n","375/375 [==============================] - 3s 7ms/step - loss: 4.5209e-09 - accuracy: 1.0000 - val_loss: 2.2513 - val_accuracy: 0.8397\n","Epoch 53/100\n","375/375 [==============================] - 2s 6ms/step - loss: 3.9778e-09 - accuracy: 1.0000 - val_loss: 2.2658 - val_accuracy: 0.8397\n","Epoch 54/100\n","375/375 [==============================] - 3s 8ms/step - loss: 3.4997e-09 - accuracy: 1.0000 - val_loss: 2.2794 - val_accuracy: 0.8398\n","Epoch 55/100\n","375/375 [==============================] - 2s 6ms/step - loss: 3.1023e-09 - accuracy: 1.0000 - val_loss: 2.2931 - val_accuracy: 0.8402\n","Epoch 56/100\n","375/375 [==============================] - 2s 6ms/step - loss: 2.7421e-09 - accuracy: 1.0000 - val_loss: 2.3063 - val_accuracy: 0.8400\n","Epoch 57/100\n","375/375 [==============================] - 3s 7ms/step - loss: 2.4289e-09 - accuracy: 1.0000 - val_loss: 2.3190 - val_accuracy: 0.8403\n","Epoch 58/100\n","375/375 [==============================] - 3s 7ms/step - loss: 2.1556e-09 - accuracy: 1.0000 - val_loss: 2.3317 - val_accuracy: 0.8405\n","Epoch 59/100\n","375/375 [==============================] - 2s 6ms/step - loss: 1.9118e-09 - accuracy: 1.0000 - val_loss: 2.3442 - val_accuracy: 0.8407\n","Epoch 60/100\n","375/375 [==============================] - 2s 6ms/step - loss: 1.6963e-09 - accuracy: 1.0000 - val_loss: 2.3562 - val_accuracy: 0.8405\n","Epoch 61/100\n","375/375 [==============================] - 2s 6ms/step - loss: 1.5047e-09 - accuracy: 1.0000 - val_loss: 2.3684 - val_accuracy: 0.8403\n","Epoch 62/100\n","375/375 [==============================] - 3s 8ms/step - loss: 1.3328e-09 - accuracy: 1.0000 - val_loss: 2.3802 - val_accuracy: 0.8398\n","Epoch 63/100\n","375/375 [==============================] - 4s 10ms/step - loss: 1.1884e-09 - accuracy: 1.0000 - val_loss: 2.3918 - val_accuracy: 0.8397\n","Epoch 64/100\n","375/375 [==============================] - 2s 6ms/step - loss: 1.0549e-09 - accuracy: 1.0000 - val_loss: 2.4033 - val_accuracy: 0.8398\n","Epoch 65/100\n","375/375 [==============================] - 2s 6ms/step - loss: 9.4383e-10 - accuracy: 1.0000 - val_loss: 2.4146 - val_accuracy: 0.8395\n","Epoch 66/100\n","375/375 [==============================] - 2s 6ms/step - loss: 8.3722e-10 - accuracy: 1.0000 - val_loss: 2.4262 - val_accuracy: 0.8393\n","Epoch 67/100\n","375/375 [==============================] - 2s 6ms/step - loss: 7.4102e-10 - accuracy: 1.0000 - val_loss: 2.4361 - val_accuracy: 0.8393\n","Epoch 68/100\n","375/375 [==============================] - 3s 7ms/step - loss: 6.7142e-10 - accuracy: 1.0000 - val_loss: 2.4477 - val_accuracy: 0.8393\n","Epoch 69/100\n","375/375 [==============================] - 3s 9ms/step - loss: 5.9918e-10 - accuracy: 1.0000 - val_loss: 2.4582 - val_accuracy: 0.8392\n","Epoch 70/100\n","375/375 [==============================] - 2s 6ms/step - loss: 5.4571e-10 - accuracy: 1.0000 - val_loss: 2.4686 - val_accuracy: 0.8390\n","Epoch 71/100\n","375/375 [==============================] - 2s 7ms/step - loss: 4.9325e-10 - accuracy: 1.0000 - val_loss: 2.4783 - val_accuracy: 0.8395\n","Epoch 72/100\n","375/375 [==============================] - 3s 7ms/step - loss: 4.5621e-10 - accuracy: 1.0000 - val_loss: 2.4878 - val_accuracy: 0.8398\n","Epoch 73/100\n","375/375 [==============================] - 3s 7ms/step - loss: 4.2151e-10 - accuracy: 1.0000 - val_loss: 2.4971 - val_accuracy: 0.8400\n","Epoch 74/100\n","375/375 [==============================] - 3s 9ms/step - loss: 3.9657e-10 - accuracy: 1.0000 - val_loss: 2.5065 - val_accuracy: 0.8397\n","Epoch 75/100\n","375/375 [==============================] - 3s 8ms/step - loss: 3.6759e-10 - accuracy: 1.0000 - val_loss: 2.5153 - val_accuracy: 0.8385\n","Epoch 76/100\n","375/375 [==============================] - 2s 6ms/step - loss: 3.5073e-10 - accuracy: 1.0000 - val_loss: 2.5244 - val_accuracy: 0.8388\n","Epoch 77/100\n","375/375 [==============================] - 2s 6ms/step - loss: 3.2970e-10 - accuracy: 1.0000 - val_loss: 2.5334 - val_accuracy: 0.8392\n","Epoch 78/100\n","375/375 [==============================] - 3s 8ms/step - loss: 3.1291e-10 - accuracy: 1.0000 - val_loss: 2.5425 - val_accuracy: 0.8392\n","Epoch 79/100\n","375/375 [==============================] - 4s 9ms/step - loss: 2.9715e-10 - accuracy: 1.0000 - val_loss: 2.5513 - val_accuracy: 0.8398\n","Epoch 80/100\n","375/375 [==============================] - 3s 7ms/step - loss: 2.8668e-10 - accuracy: 1.0000 - val_loss: 2.5602 - val_accuracy: 0.8388\n","Epoch 81/100\n","375/375 [==============================] - 2s 6ms/step - loss: 2.7569e-10 - accuracy: 1.0000 - val_loss: 2.5687 - val_accuracy: 0.8387\n","Epoch 82/100\n","375/375 [==============================] - 2s 6ms/step - loss: 2.6945e-10 - accuracy: 1.0000 - val_loss: 2.5770 - val_accuracy: 0.8393\n","Epoch 83/100\n","375/375 [==============================] - 2s 6ms/step - loss: 2.6085e-10 - accuracy: 1.0000 - val_loss: 2.5855 - val_accuracy: 0.8395\n","Epoch 84/100\n","375/375 [==============================] - 3s 8ms/step - loss: 2.5239e-10 - accuracy: 1.0000 - val_loss: 2.5936 - val_accuracy: 0.8395\n","Epoch 85/100\n","375/375 [==============================] - 3s 8ms/step - loss: 2.4906e-10 - accuracy: 1.0000 - val_loss: 2.6017 - val_accuracy: 0.8397\n","Epoch 86/100\n","375/375 [==============================] - 2s 6ms/step - loss: 2.3501e-10 - accuracy: 1.0000 - val_loss: 2.6094 - val_accuracy: 0.8393\n","Epoch 87/100\n","375/375 [==============================] - 3s 8ms/step - loss: 2.3525e-10 - accuracy: 1.0000 - val_loss: 2.6162 - val_accuracy: 0.8393\n","Epoch 88/100\n","375/375 [==============================] - 2s 6ms/step - loss: 2.2520e-10 - accuracy: 1.0000 - val_loss: 2.6236 - val_accuracy: 0.8395\n","Epoch 89/100\n","375/375 [==============================] - 3s 9ms/step - loss: 2.2324e-10 - accuracy: 1.0000 - val_loss: 2.6300 - val_accuracy: 0.8393\n","Epoch 90/100\n","375/375 [==============================] - 3s 9ms/step - loss: 2.1091e-10 - accuracy: 1.0000 - val_loss: 2.6371 - val_accuracy: 0.8392\n","Epoch 91/100\n","375/375 [==============================] - 3s 7ms/step - loss: 2.1603e-10 - accuracy: 1.0000 - val_loss: 2.6447 - val_accuracy: 0.8388\n","Epoch 92/100\n","375/375 [==============================] - 3s 7ms/step - loss: 2.1032e-10 - accuracy: 1.0000 - val_loss: 2.6504 - val_accuracy: 0.8390\n","Epoch 93/100\n","375/375 [==============================] - 2s 6ms/step - loss: 1.9719e-10 - accuracy: 1.0000 - val_loss: 2.6580 - val_accuracy: 0.8387\n","Epoch 94/100\n","375/375 [==============================] - 2s 7ms/step - loss: 2.0094e-10 - accuracy: 1.0000 - val_loss: 2.6643 - val_accuracy: 0.8387\n","Epoch 95/100\n","375/375 [==============================] - 4s 9ms/step - loss: 2.0499e-10 - accuracy: 1.0000 - val_loss: 2.6704 - val_accuracy: 0.8388\n","Epoch 96/100\n","375/375 [==============================] - 3s 7ms/step - loss: 2.0568e-10 - accuracy: 1.0000 - val_loss: 2.6756 - val_accuracy: 0.8390\n","Epoch 97/100\n","375/375 [==============================] - 2s 6ms/step - loss: 2.0064e-10 - accuracy: 1.0000 - val_loss: 2.6810 - val_accuracy: 0.8390\n","Epoch 98/100\n","375/375 [==============================] - 3s 8ms/step - loss: 1.9373e-10 - accuracy: 1.0000 - val_loss: 2.6858 - val_accuracy: 0.8377\n","Epoch 99/100\n","375/375 [==============================] - 3s 8ms/step - loss: 1.9181e-10 - accuracy: 1.0000 - val_loss: 2.6918 - val_accuracy: 0.8380\n","Epoch 100/100\n","375/375 [==============================] - 4s 10ms/step - loss: 1.7758e-10 - accuracy: 1.0000 - val_loss: 2.6967 - val_accuracy: 0.8382\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f511d636fd0>"]},"metadata":{},"execution_count":8}]}]}