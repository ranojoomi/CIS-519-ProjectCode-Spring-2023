{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ZBeMZv4EhQZIPyou09l2fUbfIVn-gLW9","timestamp":1682474034949}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"6Fam410cQUPp","executionInfo":{"status":"ok","timestamp":1682474262525,"user_tz":240,"elapsed":855,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow\n","from gensim.models.word2vec import Word2Vec\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","from keras.layers import Dense, Dropout, Conv1D, MaxPool1D, GlobalMaxPool1D, Embedding, Activation\n","from keras.preprocessing.text import Tokenizer\n","# from keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem.snowball import PorterStemmer\n","from sklearn import preprocessing\n","import gensim\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","import string\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from gensim.models import Word2Vec\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n","from tensorflow.keras.models import Sequential\n","import nltk"]},{"cell_type":"code","source":["def preprocess_text(sen):\n","    # Remove punctuations and numbers\n","    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n","\n","    # Single character removal\n","    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n","\n","    # Removing multiple spaces\n","    sentence = re.sub(r'\\s+', ' ', sentence)\n","    \n","    stops = stopwords.words('english')\n","    #print(stops)\n","    porter = PorterStemmer()\n","    for word in sentence.split():\n","        if word in stops:\n","            sentence = sentence.replace(word, '')\n","        sentence = sentence.replace(word, porter.stem(word))\n","    return sentence.lower()"],"metadata":{"id":"q5vI_KKRQhi4","executionInfo":{"status":"ok","timestamp":1682474262527,"user_tz":240,"elapsed":10,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","df = pd.read_csv('../content/drive/MyDrive/Reviews.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nfnuWQq1QhlW","executionInfo":{"status":"ok","timestamp":1682474267030,"user_tz":240,"elapsed":4512,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}},"outputId":"a76410f9-0be2-46ba-dca3-d1f7b1958df9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["\n","df = df[['Text','Score']]\n","df['Score'].isnull().sum()\n","df['Score'].isnull().sum()\n","df.drop_duplicates(subset=['Text','Score'],keep='first',inplace=True)\n","\n","def set_sent(score):\n","    if score<=2:\n","        return 0\n","    elif score==3:\n","        return 1\n","    else:\n","        return 2\n","\n","df['sentiment']=df['Score'].apply(set_sent)\n","df = df[['Text','sentiment']]\n","\n","# Separate into three sentiment groups\n","df_neg1 = df[df['sentiment']==0]\n","df_0 = df[df['sentiment']==1]\n","df_1 = df[df['sentiment']==2]\n","\n","n = 10000\n","\n","df_neg1 = df_neg1.sample(n=n, random_state=42, replace=False)\n","df_0 = df_0.sample(n=n, random_state=42, replace=False)\n","df_1 = df_1.sample(n=n, random_state=42, replace=False)\n","# print(\"df_neg1: \", df_neg1)\n","# print(\"df_0: \", df_0)\n","# print(\"df_1: \", df_1)\n","\n","sub_df = pd.concat([df_neg1, df_0, df_1], axis=0)\n","X = sub_df['Text']\n","\n","y = sub_df['sentiment']"],"metadata":{"id":"Do5l28aCRafi","executionInfo":{"status":"ok","timestamp":1682474267854,"user_tz":240,"elapsed":834,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["mes = []\n","for i in X:\n","    mes.append(i.split())\n","print(mes[:2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ptIxHOUKQhn8","executionInfo":{"status":"ok","timestamp":1682474268265,"user_tz":240,"elapsed":418,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}},"outputId":"1470ece9-c7c2-4cec-e720-edb123978795"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[['Vile', 'and', 'revolting', '\"tahini\";', 'absolutely', 'ruined', 'a', 'batch', 'a', 'hummus.', 'This', 'tahini', 'has', 'a', 'bitter,', 'metallic', 'and', 'chemical', 'like', 'taste.', 'It', 'is', 'not', 'a', 'matter', 'of', 'not', 'knowing', 'how', 'to', 'use', 'it', '(it', 'separates,', 'mix', 'it', 'up', 'just', 'like', 'natural', 'peanut', 'butter)', 'it', 'is', 'a', 'matter', 'of', 'an', 'awful', 'product.', 'Stay', 'far,', 'far', 'away', 'and', 'ignore', 'the', '5', 'star', 'reviews', 'which', 'sound', 'suspiciously', 'like', 'they', 'were', 'written', 'by', 'Joyva.', 'There', 'is', 'far', 'better', 'tahini', 'out', 'there.'], ['They', 'will', 'send', 'you', '70%', 'cocoa', 'lindt', 'chocolate', 'but', 'it', 'has', 'a', '\"new', 'recipe\".', \"It's\", '30', 'calories', 'more', 'a', 'serving,', 'all', 'sugar,', 'and', 'takes', 'like', 'crappy', 'milk', 'chocolate', \"you'd\", 'get', 'in', 'a', 'cheap', 'easter', 'bunny.', 'Has', 'none', 'of', 'the', 'cocoa', 'bite', 'that', 'it', 'used', 'to.', 'This', 'is', 'kind', 'of', 'sad,', 'since', 'this', 'chocolate', 'used', 'to', 'be', 'the', 'best', 'readily', 'available', 'dark', 'chocolate', 'on', 'the', 'market.<br', '/><br', '/>If', \"you're\", 'looking', 'for', 'a', 'dark', 'chocolate', \"that's\", 'kind', 'of', 'low', 'in', 'carbs,', 'this', \"isn't\", 'it.', 'Save', 'yourself', 'some', 'money', 'and', 'buy', 'a', 'hersey', 'bar.']]\n"]}]},{"cell_type":"code","source":["w2v_model = Word2Vec(mes, window=10, min_count=1, workers=16)\n","print(w2v_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GhChcFxvQhqO","executionInfo":{"status":"ok","timestamp":1682474292448,"user_tz":240,"elapsed":24188,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}},"outputId":"bc360210-eef5-4a33-c1c0-b2bbf56eb60d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Word2Vec<vocab=120442, vector_size=100, alpha=0.025>\n"]}]},{"cell_type":"code","source":["# Preprocess the text data\n","import nltk\n","nltk.download('stopwords')\n","import nltk\n","nltk.download('punkt')\n","stop_words = set(stopwords.words('english'))\n","def preprocess(text):\n","    text = text.lower()\n","    text = ''.join([word for word in text if word not in string.punctuation])\n","    tokens = word_tokenize(text)\n","    tokens = [word for word in tokens if word not in stop_words]\n","    return ' '.join(tokens)\n","\n","X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=0.2)\n","\n","X_train = X_train.apply(preprocess)\n","X_test = X_test.apply(preprocess)\n","\n","max_length = 100\n","\n","# Tokenize the text data\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(X_train)\n","X_train = tokenizer.texts_to_sequences(X_train)\n","X_test = tokenizer.texts_to_sequences(X_test)\n","X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n","X_test = pad_sequences(X_test, maxlen=max_length, padding='post')\n","vocab_size = len(tokenizer.word_index) + 1\n","# Create a weight matrix for the embedding layer\n","embedding_matrix = np.zeros((vocab_size, 100))\n","for word, i in tokenizer.word_index.items():\n","    if word in w2v_model.wv:\n","        embedding_matrix[i] = w2v_model.wv[word]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uugRQEMFQhtf","outputId":"d4b6e523-b677-48c1-a8ed-52ca0d7e320d","executionInfo":{"status":"ok","timestamp":1682474305438,"user_tz":240,"elapsed":13004,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras import layers\n","\n","embedding_dim = 50\n","maxlen = 100\n","\n","model = Sequential()\n","model.add(layers.Embedding(input_dim=vocab_size, \n","                           output_dim=embedding_dim, \n","                           input_length=maxlen))\n","model.add(layers.GlobalMaxPool1D())\n","model.add(layers.Dense(10, activation='relu'))\n","model.add(layers.Dense(32, activation='relu'))\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))\n"],"metadata":{"id":"Flu1HbOLPBNp","executionInfo":{"status":"ok","timestamp":1682474885050,"user_tz":240,"elapsed":383579,"user":{"displayName":"Petros Kaklamanis","userId":"02132914110414053997"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e3efe99f-f890-49c3-ddb2-4dddff74a880"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","375/375 [==============================] - 51s 127ms/step - loss: -27866.0215 - accuracy: 0.3531 - val_loss: -278851.0000 - val_accuracy: 0.3872\n","Epoch 2/100\n","375/375 [==============================] - 17s 46ms/step - loss: -10812046.0000 - accuracy: 0.3959 - val_loss: -44406216.0000 - val_accuracy: 0.4002\n","Epoch 3/100\n","375/375 [==============================] - 10s 28ms/step - loss: -230854320.0000 - accuracy: 0.4050 - val_loss: -596000576.0000 - val_accuracy: 0.3988\n","Epoch 4/100\n","375/375 [==============================] - 5s 14ms/step - loss: -1609089536.0000 - accuracy: 0.4068 - val_loss: -3237339648.0000 - val_accuracy: 0.4007\n","Epoch 5/100\n","375/375 [==============================] - 4s 12ms/step - loss: -6647575552.0000 - accuracy: 0.4106 - val_loss: -11516644352.0000 - val_accuracy: 0.4008\n","Epoch 6/100\n","375/375 [==============================] - 4s 12ms/step - loss: -19912839168.0000 - accuracy: 0.4126 - val_loss: -30719424512.0000 - val_accuracy: 0.4018\n","Epoch 7/100\n","375/375 [==============================] - 5s 13ms/step - loss: -47407304704.0000 - accuracy: 0.4150 - val_loss: -67995348992.0000 - val_accuracy: 0.4023\n","Epoch 8/100\n","375/375 [==============================] - 4s 9ms/step - loss: -98514952192.0000 - accuracy: 0.4166 - val_loss: -133919023104.0000 - val_accuracy: 0.4020\n","Epoch 9/100\n","375/375 [==============================] - 4s 10ms/step - loss: -184229576704.0000 - accuracy: 0.4148 - val_loss: -240046800896.0000 - val_accuracy: 0.4038\n","Epoch 10/100\n","375/375 [==============================] - 3s 9ms/step - loss: -317511565312.0000 - accuracy: 0.4180 - val_loss: -399755902976.0000 - val_accuracy: 0.4043\n","Epoch 11/100\n","375/375 [==============================] - 4s 10ms/step - loss: -514763849728.0000 - accuracy: 0.4203 - val_loss: -632675565568.0000 - val_accuracy: 0.4040\n","Epoch 12/100\n","375/375 [==============================] - 3s 8ms/step - loss: -794506690560.0000 - accuracy: 0.4180 - val_loss: -953359269888.0000 - val_accuracy: 0.4043\n","Epoch 13/100\n","375/375 [==============================] - 3s 8ms/step - loss: -1177303121920.0000 - accuracy: 0.4207 - val_loss: -1388085903360.0000 - val_accuracy: 0.4033\n","Epoch 14/100\n","375/375 [==============================] - 5s 13ms/step - loss: -1687328522240.0000 - accuracy: 0.4200 - val_loss: -1958000721920.0000 - val_accuracy: 0.4038\n","Epoch 15/100\n","375/375 [==============================] - 3s 8ms/step - loss: -2348591349760.0000 - accuracy: 0.4205 - val_loss: -2687905300480.0000 - val_accuracy: 0.4037\n","Epoch 16/100\n","375/375 [==============================] - 3s 8ms/step - loss: -3188049838080.0000 - accuracy: 0.4213 - val_loss: -3611780710400.0000 - val_accuracy: 0.4038\n","Epoch 17/100\n","375/375 [==============================] - 3s 8ms/step - loss: -4243947257856.0000 - accuracy: 0.4220 - val_loss: -4755446824960.0000 - val_accuracy: 0.4030\n","Epoch 18/100\n","375/375 [==============================] - 4s 11ms/step - loss: -5551936241664.0000 - accuracy: 0.4226 - val_loss: -6166689611776.0000 - val_accuracy: 0.4022\n","Epoch 19/100\n","375/375 [==============================] - 3s 7ms/step - loss: -7140323885056.0000 - accuracy: 0.4224 - val_loss: -7871591350272.0000 - val_accuracy: 0.4020\n","Epoch 20/100\n","375/375 [==============================] - 2s 5ms/step - loss: -9061231755264.0000 - accuracy: 0.4227 - val_loss: -9918740430848.0000 - val_accuracy: 0.4023\n","Epoch 21/100\n","375/375 [==============================] - 2s 6ms/step - loss: -11356654796800.0000 - accuracy: 0.4240 - val_loss: -12352628981760.0000 - val_accuracy: 0.4023\n","Epoch 22/100\n","375/375 [==============================] - 3s 7ms/step - loss: -14086011092992.0000 - accuracy: 0.4236 - val_loss: -15238684475392.0000 - val_accuracy: 0.4027\n","Epoch 23/100\n","375/375 [==============================] - 3s 8ms/step - loss: -17305854541824.0000 - accuracy: 0.4241 - val_loss: -18631322763264.0000 - val_accuracy: 0.4020\n","Epoch 24/100\n","375/375 [==============================] - 3s 7ms/step - loss: -21069993869312.0000 - accuracy: 0.4238 - val_loss: -22572951404544.0000 - val_accuracy: 0.4018\n","Epoch 25/100\n","375/375 [==============================] - 2s 6ms/step - loss: -25448396357632.0000 - accuracy: 0.4260 - val_loss: -27150612692992.0000 - val_accuracy: 0.4013\n","Epoch 26/100\n","375/375 [==============================] - 3s 7ms/step - loss: -30516086571008.0000 - accuracy: 0.4243 - val_loss: -32408508301312.0000 - val_accuracy: 0.4015\n","Epoch 27/100\n","375/375 [==============================] - 2s 7ms/step - loss: -36345372213248.0000 - accuracy: 0.4263 - val_loss: -38469850103808.0000 - val_accuracy: 0.4013\n","Epoch 28/100\n","375/375 [==============================] - 3s 9ms/step - loss: -43038810308608.0000 - accuracy: 0.4240 - val_loss: -45378669903872.0000 - val_accuracy: 0.4013\n","Epoch 29/100\n","375/375 [==============================] - 2s 6ms/step - loss: -50659730653184.0000 - accuracy: 0.4260 - val_loss: -53210366607360.0000 - val_accuracy: 0.4013\n","Epoch 30/100\n","375/375 [==============================] - 2s 6ms/step - loss: -59274982064128.0000 - accuracy: 0.4249 - val_loss: -62049262501888.0000 - val_accuracy: 0.4012\n","Epoch 31/100\n","375/375 [==============================] - 2s 6ms/step - loss: -68989069819904.0000 - accuracy: 0.4268 - val_loss: -72047002648576.0000 - val_accuracy: 0.4013\n","Epoch 32/100\n","375/375 [==============================] - 2s 5ms/step - loss: -79961847234560.0000 - accuracy: 0.4257 - val_loss: -83341776781312.0000 - val_accuracy: 0.4012\n","Epoch 33/100\n","375/375 [==============================] - 2s 6ms/step - loss: -92352609779712.0000 - accuracy: 0.4268 - val_loss: -95994943373312.0000 - val_accuracy: 0.4013\n","Epoch 34/100\n","375/375 [==============================] - 2s 6ms/step - loss: -106245159649280.0000 - accuracy: 0.4265 - val_loss: -110219447238656.0000 - val_accuracy: 0.4012\n","Epoch 35/100\n","375/375 [==============================] - 3s 7ms/step - loss: -121722560839680.0000 - accuracy: 0.4257 - val_loss: -125954085093376.0000 - val_accuracy: 0.4013\n","Epoch 36/100\n","375/375 [==============================] - 2s 6ms/step - loss: -138835094667264.0000 - accuracy: 0.4252 - val_loss: -143244658737152.0000 - val_accuracy: 0.4013\n","Epoch 37/100\n","375/375 [==============================] - 2s 6ms/step - loss: -157816576802816.0000 - accuracy: 0.4283 - val_loss: -162532199235584.0000 - val_accuracy: 0.4012\n","Epoch 38/100\n","375/375 [==============================] - 2s 6ms/step - loss: -178817456930816.0000 - accuracy: 0.4260 - val_loss: -183846662307840.0000 - val_accuracy: 0.4012\n","Epoch 39/100\n","375/375 [==============================] - 2s 7ms/step - loss: -201968974823424.0000 - accuracy: 0.4272 - val_loss: -207231232507904.0000 - val_accuracy: 0.4010\n","Epoch 40/100\n","375/375 [==============================] - 3s 9ms/step - loss: -227494082904064.0000 - accuracy: 0.4270 - val_loss: -232981675376640.0000 - val_accuracy: 0.4008\n","Epoch 41/100\n","375/375 [==============================] - 3s 9ms/step - loss: -255470677786624.0000 - accuracy: 0.4287 - val_loss: -261279017074688.0000 - val_accuracy: 0.4008\n","Epoch 42/100\n","375/375 [==============================] - 2s 5ms/step - loss: -286076396634112.0000 - accuracy: 0.4275 - val_loss: -292139179180032.0000 - val_accuracy: 0.4013\n","Epoch 43/100\n","375/375 [==============================] - 2s 5ms/step - loss: -319506106810368.0000 - accuracy: 0.4265 - val_loss: -325659083669504.0000 - val_accuracy: 0.4012\n","Epoch 44/100\n","375/375 [==============================] - 3s 7ms/step - loss: -355962560970752.0000 - accuracy: 0.4275 - val_loss: -362160332996608.0000 - val_accuracy: 0.4012\n","Epoch 45/100\n","375/375 [==============================] - 3s 7ms/step - loss: -395658158669824.0000 - accuracy: 0.4289 - val_loss: -402218486333440.0000 - val_accuracy: 0.4012\n","Epoch 46/100\n","375/375 [==============================] - 3s 8ms/step - loss: -438902506651648.0000 - accuracy: 0.4283 - val_loss: -445492093779968.0000 - val_accuracy: 0.4010\n","Epoch 47/100\n","375/375 [==============================] - 2s 5ms/step - loss: -485877302165504.0000 - accuracy: 0.4272 - val_loss: -492499739082752.0000 - val_accuracy: 0.4010\n","Epoch 48/100\n","375/375 [==============================] - 2s 5ms/step - loss: -537084385296384.0000 - accuracy: 0.4301 - val_loss: -543990793371648.0000 - val_accuracy: 0.4010\n","Epoch 49/100\n","375/375 [==============================] - 2s 6ms/step - loss: -592650726014976.0000 - accuracy: 0.4271 - val_loss: -599494622183424.0000 - val_accuracy: 0.4010\n","Epoch 50/100\n","375/375 [==============================] - 3s 7ms/step - loss: -652578136260608.0000 - accuracy: 0.4270 - val_loss: -659192788549632.0000 - val_accuracy: 0.4013\n","Epoch 51/100\n","375/375 [==============================] - 2s 6ms/step - loss: -717092168925184.0000 - accuracy: 0.4283 - val_loss: -723466571481088.0000 - val_accuracy: 0.4012\n","Epoch 52/100\n","375/375 [==============================] - 3s 8ms/step - loss: -786436697620480.0000 - accuracy: 0.4298 - val_loss: -792626953453568.0000 - val_accuracy: 0.4013\n","Epoch 53/100\n","375/375 [==============================] - 2s 5ms/step - loss: -861108797702144.0000 - accuracy: 0.4266 - val_loss: -867103565414400.0000 - val_accuracy: 0.4017\n","Epoch 54/100\n","375/375 [==============================] - 2s 6ms/step - loss: -941326841413632.0000 - accuracy: 0.4293 - val_loss: -946513551294464.0000 - val_accuracy: 0.4018\n","Epoch 55/100\n","375/375 [==============================] - 3s 7ms/step - loss: -1027446707060736.0000 - accuracy: 0.4279 - val_loss: -1032111913959424.0000 - val_accuracy: 0.4020\n","Epoch 56/100\n","375/375 [==============================] - 2s 6ms/step - loss: -1119651199188992.0000 - accuracy: 0.4288 - val_loss: -1123973278466048.0000 - val_accuracy: 0.4020\n","Epoch 57/100\n","375/375 [==============================] - 2s 7ms/step - loss: -1218302638555136.0000 - accuracy: 0.4279 - val_loss: -1221788809822208.0000 - val_accuracy: 0.4020\n","Epoch 58/100\n","375/375 [==============================] - 2s 6ms/step - loss: -1324069429444608.0000 - accuracy: 0.4296 - val_loss: -1326951218282496.0000 - val_accuracy: 0.4018\n","Epoch 59/100\n","375/375 [==============================] - 2s 5ms/step - loss: -1436851378323456.0000 - accuracy: 0.4287 - val_loss: -1438098395234304.0000 - val_accuracy: 0.4017\n","Epoch 60/100\n","375/375 [==============================] - 2s 5ms/step - loss: -1557086706073600.0000 - accuracy: 0.4286 - val_loss: -1557408694403072.0000 - val_accuracy: 0.4017\n","Epoch 61/100\n","375/375 [==============================] - 2s 6ms/step - loss: -1685465560252416.0000 - accuracy: 0.4289 - val_loss: -1684690050220032.0000 - val_accuracy: 0.4018\n","Epoch 62/100\n","375/375 [==============================] - 2s 5ms/step - loss: -1823194021363712.0000 - accuracy: 0.4313 - val_loss: -1820836486971392.0000 - val_accuracy: 0.4017\n","Epoch 63/100\n","375/375 [==============================] - 2s 6ms/step - loss: -1969679652356096.0000 - accuracy: 0.4272 - val_loss: -1965910684336128.0000 - val_accuracy: 0.4020\n","Epoch 64/100\n","375/375 [==============================] - 3s 8ms/step - loss: -2125760642940928.0000 - accuracy: 0.4305 - val_loss: -2119995857305600.0000 - val_accuracy: 0.4017\n","Epoch 65/100\n","375/375 [==============================] - 2s 5ms/step - loss: -2291602886230016.0000 - accuracy: 0.4285 - val_loss: -2284127227215872.0000 - val_accuracy: 0.4017\n","Epoch 66/100\n","375/375 [==============================] - 2s 5ms/step - loss: -2468264286355456.0000 - accuracy: 0.4308 - val_loss: -2458936422694912.0000 - val_accuracy: 0.4017\n","Epoch 67/100\n","375/375 [==============================] - 2s 5ms/step - loss: -2655402990764032.0000 - accuracy: 0.4260 - val_loss: -2642685055729664.0000 - val_accuracy: 0.4023\n","Epoch 68/100\n","375/375 [==============================] - 2s 6ms/step - loss: -2853685256257536.0000 - accuracy: 0.4308 - val_loss: -2838158681047040.0000 - val_accuracy: 0.4022\n","Epoch 69/100\n","375/375 [==============================] - 4s 11ms/step - loss: -3064136506277888.0000 - accuracy: 0.4295 - val_loss: -3045854172676096.0000 - val_accuracy: 0.4022\n","Epoch 70/100\n","375/375 [==============================] - 2s 6ms/step - loss: -3287221402599424.0000 - accuracy: 0.4283 - val_loss: -3265820117434368.0000 - val_accuracy: 0.4023\n","Epoch 71/100\n","375/375 [==============================] - 2s 6ms/step - loss: -3523255356882944.0000 - accuracy: 0.4308 - val_loss: -3498676064354304.0000 - val_accuracy: 0.4023\n","Epoch 72/100\n","375/375 [==============================] - 2s 6ms/step - loss: -3771917051887616.0000 - accuracy: 0.4297 - val_loss: -3741828390060032.0000 - val_accuracy: 0.4023\n","Epoch 73/100\n","375/375 [==============================] - 2s 6ms/step - loss: -4034576582180864.0000 - accuracy: 0.4313 - val_loss: -4000270799339520.0000 - val_accuracy: 0.4027\n","Epoch 74/100\n","375/375 [==============================] - 2s 6ms/step - loss: -4312384730562560.0000 - accuracy: 0.4290 - val_loss: -4274004365934592.0000 - val_accuracy: 0.4027\n","Epoch 75/100\n","375/375 [==============================] - 3s 8ms/step - loss: -4605714085445632.0000 - accuracy: 0.4303 - val_loss: -4561720735432704.0000 - val_accuracy: 0.4030\n","Epoch 76/100\n","375/375 [==============================] - 2s 6ms/step - loss: -4915406460420096.0000 - accuracy: 0.4305 - val_loss: -4866081445380096.0000 - val_accuracy: 0.4032\n","Epoch 77/100\n","375/375 [==============================] - 2s 6ms/step - loss: -5241110473474048.0000 - accuracy: 0.4278 - val_loss: -5184995115139072.0000 - val_accuracy: 0.4032\n","Epoch 78/100\n","375/375 [==============================] - 2s 5ms/step - loss: -5583917583171584.0000 - accuracy: 0.4333 - val_loss: -5521375880019968.0000 - val_accuracy: 0.4032\n","Epoch 79/100\n","375/375 [==============================] - 2s 6ms/step - loss: -5944264265564160.0000 - accuracy: 0.4280 - val_loss: -5874428097331200.0000 - val_accuracy: 0.4033\n","Epoch 80/100\n","375/375 [==============================] - 2s 5ms/step - loss: -6322686854692864.0000 - accuracy: 0.4314 - val_loss: -6247632301195264.0000 - val_accuracy: 0.4032\n","Epoch 81/100\n","375/375 [==============================] - 3s 7ms/step - loss: -6722162836635648.0000 - accuracy: 0.4299 - val_loss: -6638422248652800.0000 - val_accuracy: 0.4032\n","Epoch 82/100\n","375/375 [==============================] - 3s 7ms/step - loss: -7141348423499776.0000 - accuracy: 0.4307 - val_loss: -7049123664494592.0000 - val_accuracy: 0.4030\n","Epoch 83/100\n","375/375 [==============================] - 2s 6ms/step - loss: -7581265817501696.0000 - accuracy: 0.4293 - val_loss: -7479792383295488.0000 - val_accuracy: 0.4032\n","Epoch 84/100\n","375/375 [==============================] - 2s 6ms/step - loss: -8042852932124672.0000 - accuracy: 0.4299 - val_loss: -7930452027375616.0000 - val_accuracy: 0.4032\n","Epoch 85/100\n","375/375 [==============================] - 2s 6ms/step - loss: -8527711253299200.0000 - accuracy: 0.4306 - val_loss: -8406299507163136.0000 - val_accuracy: 0.4030\n","Epoch 86/100\n","375/375 [==============================] - 3s 7ms/step - loss: -9036280478302208.0000 - accuracy: 0.4298 - val_loss: -8903096763678720.0000 - val_accuracy: 0.4030\n","Epoch 87/100\n","375/375 [==============================] - 3s 7ms/step - loss: -9569724006400000.0000 - accuracy: 0.4315 - val_loss: -9424206219444224.0000 - val_accuracy: 0.4030\n","Epoch 88/100\n","375/375 [==============================] - 2s 6ms/step - loss: -10129402268483584.0000 - accuracy: 0.4300 - val_loss: -9973516430475264.0000 - val_accuracy: 0.4030\n","Epoch 89/100\n","375/375 [==============================] - 2s 5ms/step - loss: -10715308822102016.0000 - accuracy: 0.4297 - val_loss: -10545858403631104.0000 - val_accuracy: 0.4030\n","Epoch 90/100\n","375/375 [==============================] - 2s 6ms/step - loss: -11328479828115456.0000 - accuracy: 0.4302 - val_loss: -11142999517954048.0000 - val_accuracy: 0.4030\n","Epoch 91/100\n","375/375 [==============================] - 2s 5ms/step - loss: -11972086046130176.0000 - accuracy: 0.4321 - val_loss: -11772362550673408.0000 - val_accuracy: 0.4032\n","Epoch 92/100\n","375/375 [==============================] - 2s 5ms/step - loss: -12644360097103872.0000 - accuracy: 0.4298 - val_loss: -12426860805750784.0000 - val_accuracy: 0.4033\n","Epoch 93/100\n","375/375 [==============================] - 2s 5ms/step - loss: -13345542499205120.0000 - accuracy: 0.4301 - val_loss: -13111977882681344.0000 - val_accuracy: 0.4033\n","Epoch 94/100\n","375/375 [==============================] - 3s 7ms/step - loss: -14077878446587904.0000 - accuracy: 0.4308 - val_loss: -13827422797430784.0000 - val_accuracy: 0.4033\n","Epoch 95/100\n","375/375 [==============================] - 2s 6ms/step - loss: -14841946686095360.0000 - accuracy: 0.4299 - val_loss: -14572173347782656.0000 - val_accuracy: 0.4033\n","Epoch 96/100\n","375/375 [==============================] - 2s 7ms/step - loss: -15639554325217280.0000 - accuracy: 0.4311 - val_loss: -15348485465309184.0000 - val_accuracy: 0.4033\n","Epoch 97/100\n","375/375 [==============================] - 2s 6ms/step - loss: -16473582213267456.0000 - accuracy: 0.4316 - val_loss: -16163166673174528.0000 - val_accuracy: 0.4033\n","Epoch 98/100\n","375/375 [==============================] - 2s 6ms/step - loss: -17342579725041664.0000 - accuracy: 0.4295 - val_loss: -17007587308339200.0000 - val_accuracy: 0.4032\n","Epoch 99/100\n","375/375 [==============================] - 2s 6ms/step - loss: -18249243026259968.0000 - accuracy: 0.4324 - val_loss: -17892836976361472.0000 - val_accuracy: 0.4030\n","Epoch 100/100\n","375/375 [==============================] - 3s 7ms/step - loss: -19194799403827200.0000 - accuracy: 0.4300 - val_loss: -18812044803309568.0000 - val_accuracy: 0.4032\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe91f6ce760>"]},"metadata":{},"execution_count":10}]}]}