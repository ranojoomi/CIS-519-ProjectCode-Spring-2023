# CIS-519-ProjectCode-Spring-2023

## Instructions

For the Bert Models. They must be run on AWS. When the jupyter notebook opens, upload both the .ipynb files and the `Reviews.csv` file in the same directory.

For all other files. Google Colab can be used. Upload the `Reviews.csv` file into the root directory of the Google Drive of the account that is used for google colab. The code automatically mounts the drive.

## File Descriptions

`Reviews.csv`: CSV file of raw data

### Bert Files

`BERT3 (binary).ipynb`: BERT implementation using binary classification

`BERT3_10_EPOCHS_WORKING.ipynb`: BERT implementation with 10 Epochs and 1000 datapoints per classification

`BERT3_200_EPOCHS_3000_N.ipynb`: BERT implementation with 200 Epochs and 3000 datapoints per classification

`BERT3_5_EPOCHS_10000_N`: BERT implementation with 5 Epochs and 10000 datapoints per classification

### Neural Network Files

`NN 2.ipynb`: Basic Neural Netork Implementation

### Word2Vec Files

`Word2Vec_CNN accuracy33.ipynb`: Word2Vec and CNN implementation with 33% ccuracy

`Word2Vec_CNN accuracy40.ipynb`: Word2Vec and CNN implementation with 40% ccuracy

`Word2Vec_CNN.ipynb`: Word2Vec and CNN implementation

`Word2Vec_CNN2 (2-way class).ipynb`: Word2Vec and CNN implementation with binary classification

`Word2Vec_DecTree.ipynb`: Word2Vec and Decision Tree implementation

`Word2Vec_LogReg.ipynb`: Word2Vec and Logistic Regression implementation

`Word2Vec_LogRegwith2.ipynb`: Word2Vec and Logistic Regression implementation with binary classification
